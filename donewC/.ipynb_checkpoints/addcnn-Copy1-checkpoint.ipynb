{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ME1/1, Bend angle variable; number of bits optimization study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to check if it's connected\n",
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('model_name: ', 'model_MK_7bits')\n",
      "('weight_name: ', 'model_MK_7bits_weights')\n"
     ]
    }
   ],
   "source": [
    "# bit change for Andrew\n",
    "nbits_MK = 7\n",
    "model_name_MK = 'model_MK_'+str(nbits_MK)+'bits'\n",
    "weights_name_MK = model_name_MK+'_weights'\n",
    "print('model_name: ',model_name_MK)\n",
    "print('weight_name: ',weights_name_MK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Using cmssw CMSSW_10_2_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('learning_rate = ', 0.0063)\n",
      "('reg_pt_scale = ', 100.0)\n",
      "('discr_loss_weight = ', 20.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Using numpy 1.14.1\n",
      "[INFO    ] Using tensorflow 1.6.0\n",
      "Using TensorFlow backend.\n",
      "[INFO    ] Using keras 2.1.4\n",
      "[INFO    ] .. list devices: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456)]\n",
      "[INFO    ] Using scipy 1.1.0\n",
      "[INFO    ] Using sklearn 0.19.1\n",
      "[INFO    ] Using matplotlib 1.5.2\n"
     ]
    }
   ],
   "source": [
    "#MK: to import modules from different directory\n",
    "import sys\n",
    "sys.path.append('../test8/') \n",
    "\n",
    "from nn_globals import *\n",
    "from nn_encode import nlayers, nvariables\n",
    "# MK: nn_data_MK_andrew -> muon_data_split, pileup_data_split-> muon_data, pileup_data -> Encoder_MK(in nn_encode)\n",
    "from nn_data_MK_andrew import muon_data, muon_data_split, pileup_data_split, mix_training_inputs\n",
    "%matplotlib inline\n",
    "\n",
    "# MK\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_training import separate_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some variable\n",
    "adjust_scale=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x, y, w, x_mask = muon_data(infile_muon, adjust_scale=adjust_scale,\\\n",
    "                            reg_pt_scale=reg_pt_scale, nbits=nbits_MK,\\\n",
    "                            MKptmin=2.00000001,MKptmax=7000) # pt= 2.00001 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[:10])\n",
    "print(y_charge[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y is 'one over pt' here\n",
    "y_charge = np.zeros(len(y))\n",
    "for i, oopt in enumerate(y):\n",
    "    if oopt > 0:\n",
    "        y_charge[i] = 1\n",
    "#y_charge = y[y > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Loading muon data from /uscms_data/d3/mkim/MKWorkingArea/CMSSW_10_2_0/src/JL/Melrose/P2_CMSSW_10_1_5/src/L1TMuonSimulations/Analyzers/test7/histos_tba.20.npz ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 22.15171  -18.459759        nan -13.       -13.         7.\n",
      " -24.        25.843662 -16.613783 -13.         0.              nan\n",
      "        nan  10.         6.        25.843662   0.        -5.\n",
      " -16.613783   9.      ]\n",
      "clip performed\n",
      "('max: ', 63.0)\n",
      "('std: ', 16.715107)\n",
      "('min: ', -63.0)\n",
      "[-63. -62. -61. -60. -59. -58. -57. -56. -55. -54. -53. -52. -51. -50.\n",
      " -49. -48. -47. -46. -45. -44. -43. -42. -41. -40. -39. -38. -37. -36.\n",
      " -35. -34. -33. -32. -31. -30. -29. -28. -27. -26. -25. -24. -23. -22.\n",
      " -21. -20. -19. -18. -17. -16. -15. -14. -13. -12. -11. -10.  -9.  -8.\n",
      "  -7.  -6.  -5.  -4.  -3.  -2.  -1.   0.   1.   2.   3.   4.   5.   6.\n",
      "   7.   8.   9.  10.  11.  12.  13.  14.  15.  16.  17.  18.  19.  20.\n",
      "  21.  22.  23.  24.  25.  26.  27.  28.  29.  30.  31.  32.  33.  34.\n",
      "  35.  36.  37.  38.  39.  40.  41.  42.  43.  44.  45.  46.  47.  48.\n",
      "  49.  50.  51.  52.  53.  54.  55.  56.  57.  58.  59.  60.  61.  62.\n",
      "  63.]\n",
      "[ 22. -19.  nan -13. -13.   7. -24.  25. -17. -13.   0.  nan  nan  10.\n",
      "   6.  25.   0.  -5. -17.   9.]\n",
      "hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Loaded the variables with shape (3272341, 87)\n",
      "[INFO    ] Loaded the parameters with shape (3272341, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4456128   0.35296607 -0.16274202  0.18120895  0.38163847 -0.14613128\n",
      "  0.4204496  -0.34504068  0.36702442  0.26777416 -0.01917913  0.08171031\n",
      " -0.11959466 -0.13852419 -0.03859784 -0.43990272  0.06144522  0.09880041\n",
      "  0.315791   -0.17210446 -0.13967438 -0.41263407 -0.05721617 -0.15655382\n",
      "  0.38179228  0.34346595  0.03491518  0.33957767 -0.21119532  0.45849064\n",
      "  0.28485075 -0.30253837  0.0907753   0.1622468   0.26259884  0.07829022\n",
      "  0.39832547 -0.11904295  0.3484915   0.26036403 -0.3648326   0.26519024\n",
      "  0.2896746  -0.08452757  0.36592218  0.26314202  0.1006445   0.16722445\n",
      " -0.17442971  0.28956717 -0.18234989  0.47657624  0.02801067 -0.44880125\n",
      " -0.07079228  0.02312265 -0.26179618 -0.04327046 -0.10225619 -0.05485148\n",
      " -0.18771963 -0.21070865  0.27030545  0.07072856 -0.02600949  0.0689326\n",
      " -0.06825388 -0.2440411   0.14217278 -0.30874288  0.25488594  0.07101618\n",
      " -0.46704915  0.45733228 -0.14216465  0.27632806  0.23858792 -0.20598093\n",
      " -0.35857102  0.18750009 -0.08437616  0.16558152 -0.37807924  0.30705482\n",
      " -0.2912925   0.08384141 -0.14288057 -0.43426326  0.0413173   0.25379017\n",
      "  0.20178093  0.4771198   0.09205414  0.08129169 -0.17526904  0.25754705\n",
      " -0.03390468 -0.4579026   0.16450334  0.32757565]\n",
      "[ -2.2441008   2.8331335  -6.144695    5.5184913   2.620281   -6.843162\n",
      "   2.3784063  -2.898209    2.7246144   3.7344902 -52.140007   12.238358\n",
      "  -8.361577   -7.218956  -25.908184   -2.2732298  16.274658   10.121416\n",
      "   3.1666512  -5.810425   -7.159509   -2.4234548 -17.477575   -6.38758\n",
      "   2.6192253   2.9114966  28.64084     2.9448342  -4.7349534   2.1810696\n",
      "   3.5106103  -3.3053658  11.016212    6.1634502   3.80809    12.772986\n",
      "   2.5105097  -8.40033     2.8695104   3.8407764  -2.740983    3.7708778\n",
      "   3.4521494 -11.83046     2.7328215   3.8002293   9.935963    5.9799867\n",
      "  -5.7329683   3.4534302  -5.4839625   2.0983002  35.700684   -2.2281578\n",
      " -14.125834   43.24764    -3.8197656 -23.110453   -9.779359  -18.23105\n",
      "  -5.3270936  -4.7458897   3.6995184  14.138559  -38.447506   14.506924\n",
      " -14.651181   -4.0976706   7.033695   -3.2389412   3.9233234  14.081297\n",
      "  -2.1411023   2.186594   -7.0340977   3.618887    4.191327   -4.8548183\n",
      "  -2.7888477   5.3333306 -11.851688    6.039321   -2.6449482   3.2567475\n",
      "  -3.4329755  11.927279   -6.9988523  -2.3027506  24.202934    3.940263\n",
      "   4.9558697   2.0959096  10.863173   12.30138    -5.7055144   3.8827858\n",
      " -29.494453   -2.1838706   6.078904    3.0527298]\n",
      "('nbits: ', 7)\n",
      "('me1bendSF: ', -0.05982612016782184)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Loaded the encoded variables with shape (3272341, 39)\n",
      "[INFO    ] Loaded the encoded parameters with shape (3272341,)\n",
      "[INFO    ] Loaded # of training and testing events: (2257915, 1014426)\n"
     ]
    }
   ],
   "source": [
    "# Import muon data\n",
    "# 'x' is the input variables with shape (n, 87), 'y' is the q/pT with shape (n, 1)\n",
    "x_train, x_test, y_train, y_test, w_train, w_test, x_mask_train, x_mask_test = \\\n",
    "    muon_data_split(infile_muon, adjust_scale=adjust_scale, reg_pt_scale=reg_pt_scale, test_size=0.31,nbits=nbits_MK,\\\n",
    "                   MKptmin=2.00000001,MKptmax=7000) # pt= 2.00001 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (2257915,5,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-05307513e93d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train_dnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseparate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/uscms_data/d3/mkim/MKWorkingArea/CMSSW_10_2_0/src/L1TMuonSimulationsMar2017/Analyzers/MK/test8/nn_training.pyc\u001b[0m in \u001b[0;36mseparate_input\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mcnn_input0bend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m49\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m54\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mcnn_input1phi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_input0phi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mcnn_input1theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_input0theta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mcnn_input1bend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_input0bend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (2257915,5,1)"
     ]
    }
   ],
   "source": [
    "x_train_dnn, x_train_cnn = separate_input(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cnn.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cnn[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_uniq = np.unique(x_train_cnn[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_a = np.full((10,200),-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_cnn[j,:,0])\n",
    "print(np.max(x_train_cnn[j,:,0]))\n",
    "print(np.min(x_train_cnn[j,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=17\n",
    "img_a = np.full((10,200),-100)\n",
    "#egxtrain0 = x_train_cnn[j,:,0]\n",
    "#egxtrain1 = x_train_cnn[j,:,1]\n",
    "#egxtrain2 = x_train_cnn[j,:,2]\n",
    "\n",
    "\n",
    "phimin = np.nanmin(x_train_cnn[j,:,0])\n",
    "phimax = np.nanmax(x_train_cnn[j,:,0])\n",
    "print(phimin,phimax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptmin = 5\n",
    "ptmax = 6\n",
    "ooptmin = 100./ptmax\n",
    "ooptmax = 100./ptmin\n",
    "ptsel = np.where((abs(y_train)<ooptmax) & (abs(y_train) > ooptmin))\n",
    "print(ptsel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_phidif = []\n",
    "l_thetadif = []\n",
    "l_bend = []\n",
    "\n",
    "\n",
    "for j in range(163924):\n",
    "    phimin = np.min(x_train_cnn[j,:,0][np.nonzero(x_train_cnn[j,:,0])])\n",
    "    phimax = np.max(x_train_cnn[j,:,0][np.nonzero(x_train_cnn[j,:,0])])\n",
    "    thetamin = np.min(x_train_cnn[j,:,1][np.nonzero(x_train_cnn[j,:,1])])\n",
    "    thetamax = np.max(x_train_cnn[j,:,1][np.nonzero(x_train_cnn[j,:,1])])\n",
    "    phidif = int(phimax-phimin)\n",
    "    thetadif = int(thetamax-thetamin)\n",
    "    l_phidif.append(phidif)\n",
    "    l_thetadif.append(thetadif)\n",
    "    l_bend.append(x_train_cnn[j,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(l_bend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(l_thetadif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=ptsel[0][12]\n",
    "print(j)\n",
    "img_a = np.full((36,672),-64)\n",
    "egxtrain = x_train_cnn[j,:,:]\n",
    "egxtrain0 = x_train_cnn[j,:,0]\n",
    "egxtrain1 = x_train_cnn[j,:,1]\n",
    "egxtrain2 = x_train_cnn[j,:,2]\n",
    "\n",
    "i=0\n",
    "phimin = np.min(egxtrain0[np.nonzero(egxtrain0)])\n",
    "phimax = np.max(egxtrain0[np.nonzero(egxtrain0)])\n",
    "thetamin = np.min(egxtrain1[np.nonzero(egxtrain1)])\n",
    "thetamax = np.max(egxtrain1[np.nonzero(egxtrain1)])\n",
    "#print(phimin,phimax)\n",
    "#print(thetamin,thetamax)\n",
    "phicen = int(phimax-phimin)\n",
    "thetacen = int(thetamax-thetamin)\n",
    "phi_offset = int((672-phimax+phimin)/2.)\n",
    "theta_offset = int((36-thetamax+thetamin)/2.)\n",
    "zmax = 0\n",
    "for x,y,z in egxtrain:\n",
    "    i+=1\n",
    "\n",
    "    \n",
    "    #print(x,y,z)\n",
    "    if x != 0:\n",
    "        print(i)\n",
    "        #print(abs(zmax))\n",
    "        if abs(zmax) < abs(z):\n",
    "            print(True)\n",
    "            zmax = z\n",
    "        print(int(y)-int(thetamin),int(x)-int(phimin),zmax)\n",
    "        img_a[int(y)-int(thetamin)+theta_offset,int(x)-int(phimin)+phi_offset] = int(zmax)\n",
    "print(100./(y_train[j]))\n",
    "plt.figure(figsize=(45,500))\n",
    "plt.imshow(img_a,cmap='Greens', interpolation='none')\n",
    "#plt.xlim(0,100)\n",
    "#plt.ylim(0,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_images(x_train_cnn):\n",
    "    img_a = np.full((x_train_cnn.shape[0],36,672),-64)\n",
    "    for j in range(x_train_cnn.shape[0]):\n",
    "        #print(j)\n",
    "        egxtrain = x_train_cnn[j,:,:]\n",
    "        egxtrain0 = x_train_cnn[j,:,0]\n",
    "        egxtrain1 = x_train_cnn[j,:,1]\n",
    "\n",
    "        #i=0\n",
    "        phimin = np.min(egxtrain0[np.nonzero(egxtrain0)])\n",
    "        phimax = np.max(egxtrain0[np.nonzero(egxtrain0)])\n",
    "        thetamin = np.min(egxtrain1[np.nonzero(egxtrain1)])\n",
    "        thetamax = np.max(egxtrain1[np.nonzero(egxtrain1)])\n",
    "        phi_offset = int((672-phimax+phimin)/2.)\n",
    "        theta_offset = int((36-thetamax+thetamin)/2.)\n",
    "        zmax = 0\n",
    "        for x,y,z in egxtrain:\n",
    "            #i+=1\n",
    "\n",
    "\n",
    "            #print(x,y,z)\n",
    "            if x != 0:\n",
    "                #print(i)\n",
    "                #print(abs(zmax))\n",
    "                if abs(zmax) < abs(z):\n",
    "                    #print(True)\n",
    "                    zmax = z\n",
    "                #print(int(y)-int(thetamin),int(x)-int(phimin),zmax)\n",
    "                img_a[j,int(y)-int(thetamin)+theta_offset,int(x)-int(phimin)+phi_offset] = int(zmax)\n",
    "    return img_a\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = make_images(x_train_cnn[:10000])\n",
    "train_labels = y_train[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((10000, 36, 672, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32') / 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(10, (3, 100), activation='tanh', input_shape=(36, 672,1)))\n",
    "model.add(layers.MaxPooling2D((2, 4)))\n",
    "model.add(layers.Conv2D(10, (2, 50), activation='tanh'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(10, (2, 25), activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='tanh'))\n",
    "#model.add(layers.Dense(10, activation='tanh'))\n",
    "model.add(layers.Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              metrics=['mae'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(45,500))\n",
    "plt.imshow(images1[3],cmap='Greens', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(phi_uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0,1,2,3,4,5]:\n",
    "    print(x_train[i,39:44])\n",
    "    print(x_train[i,39+5:44+5])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pileup data\n",
    "# 'x' is the input variables with shape (n, 87), 'aux' is pileup info with shape (n, 4)\n",
    "pu_x_train, pu_x_test, pu_aux_train, pu_aux_test, pu_w_train, pu_w_test, pu_x_mask_train, pu_x_mask_test = \\\n",
    "    pileup_data_split(infile_pileup, adjust_scale=adjust_scale, reg_pt_scale=reg_pt_scale, test_job=131,nbits=nbits_MK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_charge(y):\n",
    "    # y is 'one over pt' here\n",
    "    y_charge = np.zeros(len(y))\n",
    "    for i, oopt in enumerate(y):\n",
    "        if oopt > 0:\n",
    "            y_charge[i] = 1.\n",
    "    return y_charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_charge = get_charge(y_train)\n",
    "y_test_charge = get_charge(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add output nodes for pileup data; add_noise means adding pileup\n",
    "if add_noise:\n",
    "    # signal\n",
    "    labels = np.where(np.abs(1.0/y_train) >= discr_pt_cut/reg_pt_scale, 1., mask_value)\n",
    "    y_train = [y_train, labels.astype(np.float32), y_train_charge]\n",
    "    labels = np.where(np.abs(1.0/y_test) >= discr_pt_cut/reg_pt_scale, 1., mask_value)\n",
    "    y_test = [y_test, labels.astype(np.float32), y_test_charge]\n",
    "\n",
    "    # charge masking value\n",
    "    MKmask_value = 0.5\n",
    "    #pile-ups\n",
    "    # (mask(since there's no pt), (yes pile up =0;no pile up=1), no chage=1)\n",
    "    pu_y_train = [np.full((pu_x_train.shape[0],), mask_value, dtype=np.float32),\\\n",
    "                  np.zeros((pu_x_train.shape[0],), dtype=np.float32),\\\n",
    "                  np.full((pu_x_train.shape[0],), MKmask_value, dtype=np.float32)]\n",
    "    pu_y_test = [np.full((pu_x_test.shape[0],), mask_value, dtype=np.float32),\\\n",
    "                 np.zeros((pu_x_test.shape[0],), dtype=np.float32),\\\n",
    "                 np.full((pu_x_test.shape[0],), MKmask_value, dtype=np.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding \n",
    "if add_noise:\n",
    "    x_train_new, y_train_new = mix_training_inputs(x_train, y_train, pu_x_train,\\\n",
    "                                                   pu_y_train, pu_aux_train, discr_pt_cut=discr_pt_cut, tile=5)\n",
    "else:\n",
    "    raise Exception('add_noise must be set to True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_training import separate_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_newer = separate_input(x_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hello, what do you want to train today?\n",
    "from nn_models import (create_model, create_model_bn, create_model_pruned,\n",
    "                       create_model_sequential, create_model_sequential_bn,\n",
    "                       lr_decay, modelbestcheck, modelbestcheck_weights,\n",
    "                       create_model_bn_charge, create_model_bn_charge_cnn)\n",
    "from nn_training import train_model\n",
    "from nn_pruning import prune_model\n",
    "assert(keras.backend.backend() == 'tensorflow')\n",
    "training_seq    = False\n",
    "training_func   = False\n",
    "training_bn     = True\n",
    "training_pruned = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with Batch Normalization\n",
    "# Model creation\n",
    "# 'model' is a densely connected NN with 3 hidden layers and 2 output nodes, q/pT and PU discriminator\n",
    "model = create_model_bn_charge_cnn(nvariables=nvariables, lr=learning_rate, clipnorm=gradient_clip_norm, l1_reg=l1_reg, l2_reg=l2_reg, discr_loss_weight=discr_loss_weight,\n",
    "                        nodes1=60, nodes2=50, nodes3=60)\n",
    "\n",
    "logger.info('Training model with l1_reg: {0} l2_reg: {0}'.format(l1_reg, l2_reg))\n",
    "\n",
    "# training Model\n",
    "normal_epochs = 300\n",
    "normal_batch_size = 256*4*2\n",
    "history = train_model(model, x_train_newer, y_train_new,\n",
    "                      model_name=model_name_MK, epochs=normal_epochs, batch_size=normal_batch_size,\n",
    "                      callbacks=[lr_decay], validation_split=0.1, verbose=1)\n",
    "#,modelbestcheck,modelbestcheck_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [len(history.history['loss']), history.history['loss'][-1], history.history['regr_loss'][-1], history.history['discr_loss'][-1], \n",
    "           history.history['val_loss'][-1], history.history['val_regr_loss'][-1], history.history['val_discr_loss'][-1]]\n",
    "logger.info('Epoch {0}/{0} - loss: {1} - regr_loss: {2} - discr_loss: {3} - val_loss: {4} - val_regr_loss: {5} - val_discr_loss: {6}'.format(*metrics))\n",
    "\n",
    "metrics2= [history.history['charge_prediction_loss'][-1],history.history['val_charge_prediction_loss'][-1]]\n",
    "logger.info('charge_prediction_loss: {0}, val_charge_prediction_loss: {1}'.format(*metrics2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Setup matplotlib\n",
    "plt.style.use('tdrstyle.mplstyle')\n",
    "\n",
    "from nn_plotting import (gaus, fit_gaus, np_printoptions, \\\n",
    "                         find_efficiency_errors)\n",
    "\n",
    "eps = 1e-7\n",
    "my_cmap = plt.cm.viridis\n",
    "my_cmap.set_under('w',1)\n",
    "my_palette = (\"#377eb8\", \"#e41a1c\", \"#984ea3\", \"#ff7f00\", \"#4daf4a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and predict outputs\n",
    "from nn_models import load_my_model, update_keras_custom_objects\n",
    "update_keras_custom_objects()\n",
    "#K.set_learning_phase(0)\n",
    "loaded_model = load_my_model(name=model_name_MK, weights_name=weights_name_MK)\n",
    "loaded_model.trainable = False\n",
    "assert not loaded_model.updates\n",
    "\n",
    "nentries_test = x_test.shape[0]//4\n",
    "\n",
    "# Prepare y_test_true, y_test_meas\n",
    "y_test_true = y_test\n",
    "if isinstance(y_test_true, list):\n",
    "  y_test_true = y_test_true[0]\n",
    "y_test_true = y_test_true[:nentries_test].copy()\n",
    "y_test_true = y_test_true.reshape(-1)\n",
    "y_test_true /= reg_pt_scale\n",
    "\n",
    "x_test4 = x_test[:nentries_test]\n",
    "\n",
    "\n",
    "#predict\n",
    "y_test_meas = loaded_model.predict(separate_input(x_test4), batch_size=4096)\n",
    "# [0]pt [1]\n",
    "if isinstance(y_test_meas, list):\n",
    "    y_test_meas = y_test_meas[0]\n",
    "y_test_meas = y_test_meas.reshape(-1)\n",
    "y_test_meas /= reg_pt_scale\n",
    "#print y_test_true.shape, y_test_true\n",
    "#print y_test_meas.shape, y_test_meas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signed_pt(y):\n",
    "    # pt, disc, charge\n",
    "    oopt_pred = y[0]\n",
    "    charge_pred = y[2]\n",
    "    return oopt_pred*(2*charge_pred-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = np.array([0,1,2,3,4])\n",
    "ccc = np.array([0,1,2,3,4])\n",
    "bbb = np.array([0,1,0,1,1])\n",
    "\n",
    "yddd = [aaa,ccc,bbb]\n",
    "print(signed_pt(yddd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aaa*(2*bbb-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_test_true[:10])\n",
    "#print(y_test_meas[:10])\n",
    "ptlisto = [2.0001,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100,\\\n",
    "           200,300,400,500,600,700,800,900,1000]\n",
    "signo = []\n",
    "for i in range(len(ptlisto)-1):\n",
    "    vapt=ptlisto[i]\n",
    "    vanextpt=ptlisto[i+1]\n",
    "    va=1/float(vapt)\n",
    "    vanext=1/float(vanextpt)\n",
    "    stepva=vanext\n",
    "    ytt=y_test_true[((y_test_true>va) & (y_test_true<va+stepva)) |\\\n",
    "                    ((y_test_true< -va) & (y_test_true> -(va+stepva)))]\n",
    "    #print(ytt.size)\n",
    "    ytm=y_test_meas[((y_test_true>va) & (y_test_true<va+stepva)) |\\\n",
    "                    ((y_test_true< -va) & (y_test_true> -(va+stepva)))]\n",
    "    #print(ytm.size)\n",
    "    signarray = ytt*ytm\n",
    "    #print(signarray[:10])\n",
    "    signbool=signarray>=0\n",
    "    #print(signbool[:100])\n",
    "    numtrue = np.sum(signbool)\n",
    "    #print(numtrue)\n",
    "    arrsize = signbool.size\n",
    "    #print(arrsize)\n",
    "    signo.append(float(numtrue)/arrsize)\n",
    "    print(ptlisto[i],ptlisto[i+1],float(numtrue)/arrsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ptlisto[:-1],signo)\n",
    "plt.ylim([0.55,1.00])\n",
    "plt.xlim([0,30])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Delta(q/pT)\n",
    "plt.figure()\n",
    "yy = y_test_meas - y_test_true\n",
    "hist, edges, _ = plt.hist(yy, bins=100, range=(-0.3,0.3-eps), histtype='stepfilled', facecolor='g', alpha=0.6)\n",
    "plt.xlabel(r'$\\Delta(q/p_{T})_{\\mathrm{meas-true}}$ [1/GeV]')\n",
    "plt.ylabel(r'entries')\n",
    "logger.info('# of entries: {0}, mean: {1}, std: {2}'.format(len(yy), np.mean(yy), np.std(yy[np.abs(yy)<0.3])))\n",
    "\n",
    "popt = fit_gaus(hist, edges, mu=np.mean(yy), sig=np.std(yy[np.abs(yy)<0.3]))\n",
    "logger.info('gaus fit (a, mu, sig): {0}'.format(popt))\n",
    "xdata = (edges[1:] + edges[:-1])/2\n",
    "plt.plot(xdata, gaus(xdata, popt[0], popt[1], popt[2]), color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Delta(q/pT) / pT\n",
    "plt.figure()\n",
    "yy = (np.abs(1.0/y_test_meas) - np.abs(1.0/y_test_true))/np.abs(1.0/y_test_true)\n",
    "hist, edges, _ = plt.hist(yy, bins=100, range=(-2,2), histtype='stepfilled', facecolor='g', alpha=0.6)\n",
    "plt.xlabel(r'$\\Delta(p_{T})_{\\mathrm{meas-true}} / p_{T}$')\n",
    "plt.ylabel(r'entries')\n",
    "logger.info('# of entries: {0}, mean: {1}, std: {2}'.format(len(yy), np.mean(yy), np.std(yy[np.abs(yy)<2])))\n",
    "\n",
    "popt = fit_gaus(hist, edges, mu=np.mean(yy), sig=np.std(yy[np.abs(yy)<1.5]))\n",
    "logger.info('gaus fit (a, mu, sig): {0}'.format(popt))\n",
    "xdata = (edges[1:] + edges[:-1])/2\n",
    "plt.plot(xdata, gaus(xdata, popt[0], popt[1], popt[2]), color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot resolution plots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(5.4,5.4), tight_layout=True)\n",
    "\n",
    "axs[0,0].hist2d(y_test_true, y_test_meas, bins=(100,100), range=((-0.5,0.5),(-0.5,0.5)), vmin=1, cmap=my_cmap)\n",
    "axs[0,0].set_xlabel(r'true $q/p_{T}$ [1/GeV]', fontsize=10)\n",
    "axs[0,0].set_ylabel(r'meas $q/p_{T}$ [1/GeV]', fontsize=10)\n",
    "\n",
    "yy = y_test_meas - y_test_true\n",
    "axs[0,1].hist2d(y_test_true, yy, bins=(100,100), range=((-0.5,0.5),(-0.2,0.2)), vmin=1, cmap=my_cmap)\n",
    "axs[0,1].set_xlabel(r'true $q/p_{T}$ [1/GeV]', fontsize=10)\n",
    "axs[0,1].set_ylabel(r'$\\Delta(q/p_{T})_{\\mathrm{meas-true}}$ [1/GeV]', fontsize=10)\n",
    "\n",
    "yy = (y_test_meas - y_test_true)/np.abs(y_test_true)\n",
    "axs[1,0].hist2d(y_test_true, yy, bins=(100,100), range=((-0.5,0.5),(-2,2)), vmin=1, cmap=my_cmap)\n",
    "axs[1,0].set_xlabel(r'true $q/p_{T}$ [1/GeV]', fontsize=10)\n",
    "axs[1,0].set_ylabel(r'$\\Delta(q/p_{T})_{\\mathrm{meas-true}} \\cdot (q \\cdot p_{T})$', fontsize=10)\n",
    "\n",
    "yy = (np.abs(1.0/y_test_meas) - np.abs(1.0/y_test_true))/np.abs(1.0/y_test_true)\n",
    "axs[1,1].hist2d(y_test_true, yy, bins=(100,100), range=((-0.5,0.5),(-2,2)), vmin=1, cmap=my_cmap)\n",
    "axs[1,1].set_xlabel(r'true $q/p_{T}$ [1/GeV]', fontsize=10)\n",
    "axs[1,1].set_ylabel(r'$\\Delta(p_{T})_{\\mathrm{meas-true}} / p_{T}$', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make better resolution plot\n",
    "xx = np.abs(y_test_true)\n",
    "yy = (np.abs(1.0/y_test_meas) - np.abs(1.0/y_test_true))/np.abs(1.0/y_test_true)\n",
    "\n",
    "nbinsx = 100 #MK\n",
    "xedges = np.linspace(1/float(7000), 1/float(2.0000001), num=nbinsx+1) # MK: 1/pt min max\n",
    "inds = np.digitize(xx, xedges[1:])\n",
    "\n",
    "xxx = np.zeros(nbinsx, dtype=np.float32)\n",
    "yyy = np.zeros(nbinsx, dtype=np.float32)\n",
    "for i in xrange(nbinsx):\n",
    "  xx_i = xx[inds==i]\n",
    "  pt = np.mean(xx_i)\n",
    "  pt = 1.0/pt\n",
    "  \n",
    "  yy_i = yy[inds==i]\n",
    "  yy_i = yy_i[(-1 <= yy_i) & (yy_i <= 1.2)]\n",
    "  mu, sig = np.mean(yy_i), np.std(yy_i)\n",
    "  assert(np.abs(mu) < 1)\n",
    "  assert(np.abs(sig) < 2)\n",
    "  \n",
    "  hist, edges = np.histogram(yy_i, bins=100, range=(-2,2))\n",
    "  #popt = fit_gaus(hist, edges, mu=mu, sig=sig)\n",
    "  popt = fit_gaus(hist, edges, mu=0.0, sig=0.2)\n",
    "  #print i, len(xx_i), mu, sig, pt, popt\n",
    "  \n",
    "  if 20. < pt < 22.:\n",
    "    xx_20GeV, yy_20GeV, popt_20GeV = xx_i, yy_i, popt\n",
    "  \n",
    "  xxx[i] = pt\n",
    "  yyy[i] = popt[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(5.4,5.4/2), tight_layout=True)\n",
    "\n",
    "#axs[0].hist2d(xx, yy, bins=(100,100), range=((0,0.5),(-1,3)), vmin=1, cmap=my_cmap)\n",
    "#axs[0].set_xlabel(r'true $1/p_{T}$ [1/GeV]', fontsize=10)\n",
    "#axs[0].set_ylabel(r'$\\Delta(p_{T})_{\\mathrm{meas-true}} / p_{T}$', fontsize=10)\n",
    "\n",
    "hist, edges, _ = axs[0].hist(yy_20GeV, bins=100, range=(-2,2), histtype='stepfilled', facecolor='g', alpha=0.6)\n",
    "popt = fit_gaus(hist, edges, mu=0.0, sig=0.2)\n",
    "axs[0].plot(xdata, gaus(xdata, popt[0], popt[1], popt[2]), color='g')\n",
    "axs[0].text(0.05, 0.9, r'@ 20GeV', transform=axs[0].transAxes, fontsize=8)\n",
    "axs[0].text(0.05, 0.8, r'$\\mu$ = {0:.4f}'.format(popt[1]), transform=axs[0].transAxes, fontsize=8)\n",
    "axs[0].text(0.05, 0.7, r'$\\sigma$ = {0:.4f}'.format(popt[2]), transform=axs[0].transAxes, fontsize=8)\n",
    "axs[0].set_xlabel(r'$\\Delta(p_{T})_{\\mathrm{meas-true}} / p_{T}$', fontsize=10)\n",
    "axs[0].set_ylabel(r'entries', fontsize=10)\n",
    "logger.info('gaus fit (a, mu, sig): {0}'.format(popt))\n",
    "\n",
    "#fig, axs = plt.subplots(1, 2, figsize=(5.4,5.4/2), tight_layout=True) # remove when ploting 2\n",
    "axs[1].scatter(xxx, yyy, color='g', alpha=0.6)\n",
    "axs[1].set_xlim(1,50)\n",
    "axs[1].set_ylim(0,0.6+eps)\n",
    "axs[1].set_xlabel(r'true $p_{T}$ [GeV]', fontsize=10)\n",
    "axs[1].set_ylabel(r'$\\Delta(p_{T}) / p_{T}$ resolution', fontsize=10)\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].set_xticks(range(1,9) + range(10,50,10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock minbias pT spectrum\n",
    "xx = np.linspace(0.1, 49.1, num=50)\n",
    "#reweight = lambda x: 5.5 * np.power(x,-3)\n",
    "#reweight = lambda x: 11 * np.power(x,-4)\n",
    "reweight = lambda x: 7.778 * np.power(x,-3.5)\n",
    "xw = np.fromiter((reweight(xi) for xi in xx), xx.dtype)\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.hist(xx, bins=50, range=(0,50), weights=xw, histtype='stepfilled', facecolor='g', alpha=0.6)\n",
    "plt.xlabel(r'true $p_{T}$ [GeV]')\n",
    "plt.ylabel(r'weighted entries')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict 20 GeV rates with 90% coverage\n",
    "xx = np.abs(1.0/y_test_true)\n",
    "yy = np.abs(1.0/y_test_meas)\n",
    "\n",
    "reweight = lambda x, y, thresh: 7.778 * np.power(x,-2.5) if y >= thresh else 0.  # -2.5 instead of -3.5 because the parent distribution is already 1/pT-weighted\n",
    "\n",
    "nbinsx = 20\n",
    "xedges = np.linspace(2, 42, num=nbinsx+1)\n",
    "inds = np.digitize(xx, xedges[1:])\n",
    "\n",
    "xxx = np.zeros(nbinsx, dtype=np.float32)\n",
    "for i in xrange(nbinsx):\n",
    "  xx_i = xx[inds==i]\n",
    "  yy_i = yy[inds==i]\n",
    "  pct = np.percentile(yy_i, [10, 50, 90], overwrite_input=True)\n",
    "  #print np.mean(xx_i), len(xx_i), pct\n",
    "  \n",
    "  xxx[i] = pct[0]\n",
    "\n",
    "ind_20GeV = np.digitize(20., xedges[1:])\n",
    "thresh_20GeV = xxx[ind_20GeV]\n",
    "yw = np.fromiter((reweight(xi, yi, thresh_20GeV) for (xi, yi) in zip(xx, yy)), xx.dtype)\n",
    "logger.info(\"20 GeV threshold {0} rate {1}\".format(thresh_20GeV, np.sum(yw)))\n",
    "\n",
    "ind_22GeV = np.digitize(22., xedges[1:])\n",
    "thresh_22GeV = xxx[ind_22GeV]\n",
    "yw = np.fromiter((reweight(xi, yi, thresh_22GeV) for (xi, yi) in zip(xx, yy)), xx.dtype)\n",
    "logger.info(\"22 GeV threshold {0} rate {1}\".format(thresh_22GeV, np.sum(yw)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Use the predicted rate as loss function/scoring in training\n",
    "if True:\n",
    "  from nn_models import NewKerasRegressor\n",
    "  estimator = NewKerasRegressor(build_fn=create_model_sequential, reg_pt_scale=reg_pt_scale, min_pt=20., max_pt=22., coverage=90.,\n",
    "                                nvariables=nvariables, lr=learning_rate, clipnorm=gradient_clip_norm)\n",
    "\n",
    "  estimator.model = loaded_model\n",
    "\n",
    "  # Cross check\n",
    "  print estimator.score2(x_test[:nentries_test], y_test[0][:nentries_test] if isinstance(y_test, list) else y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test4 = x_test[:nentries_test]\n",
    "#y_test_meas = loaded_model.predict(separate_input(x_test4), batch_size=4096)\n",
    "\n",
    "# Prepare y_test_true, y_test_meas (again)\n",
    "y_test_true = [y_test[0][:nentries_test].copy(), y_test[1][:nentries_test].copy()]\n",
    "y_test_meas = loaded_model.predict(separate_input(x_test4), batch_size=4096)\n",
    "\n",
    "y_test_sel = (y_test_true[1] != mask_value)  # skip low pT muons\n",
    "y_test_true[0] /= reg_pt_scale\n",
    "y_test_meas[0] /= reg_pt_scale\n",
    "#print y_test_true[0].shape, y_test_true[0], y_test_true[1].shape, y_test_true[1]\n",
    "#print y_test_meas[0].shape, y_test_meas[0], y_test_meas[1].shape, y_test_meas[1]\n",
    "\n",
    "# Prepare pu_y_test_true, pu_y_test_meas\n",
    "pu_y_test_sel = ~(pu_aux_test[:,2] > discr_pt_cut)  # veto PU events with high-pT tracks\n",
    "pu_y_test_true = [pu_y_test[0].copy(), pu_y_test[1].copy()]\n",
    "pu_y_test_meas = loaded_model.predict(separate_input(pu_x_test), batch_size=4096)\n",
    "#pu_y_test_true[0] /= reg_pt_scale\n",
    "pu_y_test_meas[0] /= reg_pt_scale\n",
    "#print pu_y_test_true[0].shape, pu_y_test_true[0], pu_y_test_true[1].shape, pu_y_test_true[1]\n",
    "#print pu_y_test_meas[0].shape, pu_y_test_meas[0], pu_y_test_meas[1].shape, pu_y_test_meas[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_singlemu(x_mask):\n",
    "  valid = ~x_mask\n",
    "  mode = np.int32(0)\n",
    "  if np.any([valid[0], valid[1], valid[5], valid[9], valid[11]]):   # ME1/1, ME1/2, RE1/2, GE1/1, ME0\n",
    "    mode |= (1<<3)\n",
    "  if np.any([valid[2], valid[6], valid[10]]):  # ME2, RE2, GE2/1\n",
    "    mode |= (1<<2)\n",
    "  if np.any([valid[3], valid[7]]):  # ME3, RE3\n",
    "    mode |= (1<<1)\n",
    "  if np.any([valid[4], valid[8]]):  # ME4, RE4\n",
    "    mode |= (1<<0)\n",
    "  return mode in (11,13,14,15)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Calculate losses (1)\n",
    "from nn_models import masked_huber_loss, masked_binary_crossentropy\n",
    "\n",
    "regr_y_true = (y_test_true[0] * reg_pt_scale)[:, np.newaxis]\n",
    "regr_y_pred = (y_test_meas[0] * reg_pt_scale)\n",
    "assert(regr_y_true.ndim == 2 and regr_y_pred.ndim == 2)\n",
    "regr_loss = K.mean(masked_huber_loss(regr_y_true, regr_y_pred))\n",
    "\n",
    "num_samples = y_test_true[1].shape[0]\n",
    "pu_num_samples = pu_y_test_true[1][pu_y_test_sel].shape[0]\n",
    "index_array = np.random.randint(num_samples, size=pu_num_samples)\n",
    "discr_y_true = np.concatenate((y_test_true[1][index_array], pu_y_test_true[1][pu_y_test_sel]))[:, np.newaxis]\n",
    "discr_y_pred = np.concatenate((y_test_meas[1][index_array], pu_y_test_meas[1][pu_y_test_sel]))\n",
    "assert(discr_y_true.ndim == 2 and discr_y_pred.ndim == 2)\n",
    "discr_y_true = K.cast(discr_y_true, dtype=np.float32)\n",
    "discr_y_pred = K.cast(discr_y_pred, dtype=np.float32)\n",
    "discr_loss = K.mean(masked_binary_crossentropy(discr_y_true, discr_y_pred))\n",
    "\n",
    "sess = K.get_session()\n",
    "logger.info('Evaluated losses - regr_loss: {0} - discr_loss: {1}'.format(*sess.run([regr_loss,discr_loss])))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Calculate losses (2)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(5.4,5.4/2), tight_layout=True)\n",
    "\n",
    "yy = masked_huber_loss(regr_y_true, regr_y_pred)\n",
    "yy = sess.run(yy)\n",
    "axs[0].hist2d(regr_y_true[:,0], yy, bins=(100,40), range=((-50,50),(0,40)), vmin=1, cmap=my_cmap)\n",
    "\n",
    "xx = discr_y_true\n",
    "yy = masked_binary_crossentropy(discr_y_true, discr_y_pred)\n",
    "xx, yy = sess.run([xx, yy])\n",
    "axs[1].hist2d(xx[:,0], yy, bins=(10,40), range=((0,1),(0,40)), vmin=1, cmap=my_cmap)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot discriminator\n",
    "plt.figure()\n",
    "xx = pu_y_test_meas[1][pu_y_test_sel]\n",
    "xw = np.ones_like(xx)/float(len(xx))\n",
    "yy = y_test_meas[1][y_test_sel]\n",
    "yw = np.ones_like(yy)/float(len(yy))\n",
    "plt.hist(xx, bins=50, range=(0,1), weights=xw, histtype='step', color='black', lw=1.5)\n",
    "plt.hist(yy, bins=50, range=(0,1), weights=yw, histtype='step', color='red', lw=1.5)\n",
    "plt.xlabel(r'PU discriminator')\n",
    "plt.ylabel(r'entries')\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(1e-5, 2)\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "# Calculate separation score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "xx = np.concatenate((y_test_true[1][y_test_sel], pu_y_test_true[1][pu_y_test_sel]))\n",
    "yy = np.concatenate((y_test_meas[1][y_test_sel], pu_y_test_meas[1][pu_y_test_sel]))\n",
    "zz = np.concatenate((y_test_meas[0][y_test_sel], pu_y_test_meas[0][pu_y_test_sel]))\n",
    "tt = np.concatenate((x_mask_test[:nentries_test][y_test_sel], pu_x_mask_test[pu_y_test_sel]))\n",
    "\n",
    "tt = np.apply_along_axis(roc_singlemu, 1, tt)  # require SingleMu quality\n",
    "xx = xx[:, np.newaxis]\n",
    "xx = xx[tt]\n",
    "yy = yy[tt]\n",
    "zz = zz[tt]\n",
    "\n",
    "zzz = np.abs(1.0/zz) > discr_pt_cut  # meas pT > 8 GeV\n",
    "xxx = xx[zzz]\n",
    "yyy = yy[zzz]\n",
    "\n",
    "fpr, tpr, thresh = roc_curve(xxx, yyy)  # (y_true, y_meas)\n",
    "auc = roc_auc_score(xxx, yyy)           # (y_true, y_meas)\n",
    "\n",
    "idx = np.searchsorted(tpr, [0.9, 0.925, 0.95, 0.97, 0.975, 0.98, 0.985, 0.99, 0.999])\n",
    "logger.info(\"auc: {0}\".format(auc))\n",
    "logger.info(\"thr: {0}\".format(np.array2string(thresh[idx], separator=', ', precision=4, floatmode='fixed')))\n",
    "logger.info(\"tpr: {0}\".format(np.array2string(tpr[idx], separator=', ', precision=4, floatmode='fixed')))\n",
    "logger.info(\"fpr: {0}\".format(np.array2string(fpr[idx], separator=', ', precision=4, floatmode='fixed')))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, 'r')\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.text(0.06, 0.93, r'auc = %f' % auc, fontsize=12)\n",
    "plt.xlim(0.0,0.21)\n",
    "plt.ylim(0.9,1.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC (for pT > 14 GeV)\n",
    "zzz = np.abs(1.0/zz) > 14\n",
    "xxx = xx[zzz]\n",
    "yyy = yy[zzz]\n",
    "\n",
    "fpr, tpr, thresh = roc_curve(xxx, yyy)  # (y_true, y_meas)\n",
    "auc = roc_auc_score(xxx, yyy)           # (y_true, y_meas)\n",
    "\n",
    "idx = np.searchsorted(tpr, [0.9, 0.925, 0.95, 0.97, 0.975, 0.98, 0.985, 0.99, 0.999])\n",
    "logger.info(\"auc: {0}\".format(auc))\n",
    "logger.info(\"thr: {0}\".format(np.array2string(thresh[idx], separator=', ', precision=4, floatmode='fixed')))\n",
    "logger.info(\"tpr: {0}\".format(np.array2string(tpr[idx], separator=', ', precision=4, floatmode='fixed')))\n",
    "logger.info(\"fpr: {0}\".format(np.array2string(fpr[idx], separator=', ', precision=4, floatmode='fixed')))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, 'r')\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.text(0.06, 0.93, r'auc = %f' % auc, fontsize=12)\n",
    "plt.xlim(0.0,0.11)\n",
    "plt.ylim(0.9,1.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency & Rates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build track producer\n",
    "\n",
    "from six.moves import range, zip, map, filter\n",
    "\n",
    "pt_bins = (-0.5, -0.365, -0.26, -0.155, -0.07, 0.07, 0.155, 0.26, 0.365, 0.5)\n",
    "\n",
    "theta_to_eta_lut = [\n",
    "   2.599, 2.566, 2.534, 2.503, 2.473, 2.444, 2.415, 2.388, 2.361, 2.334,\n",
    "   2.309, 2.284, 2.259, 2.236, 2.212, 2.19 , 2.167, 2.145, 2.124, 2.103,\n",
    "   2.083, 2.063, 2.043, 2.024, 2.005, 1.986, 1.968, 1.95 , 1.932, 1.915,\n",
    "   1.898, 1.881, 1.864, 1.848, 1.832, 1.816, 1.8  , 1.785, 1.77 , 1.755,\n",
    "   1.74 , 1.726, 1.711, 1.697, 1.683, 1.67 , 1.656, 1.642, 1.629, 1.616,\n",
    "   1.603, 1.59 , 1.578, 1.565, 1.553, 1.541, 1.529, 1.517, 1.505, 1.493,\n",
    "   1.482, 1.47 , 1.459, 1.448, 1.436, 1.425, 1.415, 1.404, 1.393, 1.382,\n",
    "   1.372, 1.362, 1.351, 1.341, 1.331, 1.321, 1.311, 1.301, 1.291, 1.282,\n",
    "   1.272, 1.262, 1.253, 1.244, 1.234, 1.225, 1.216, 1.207, 1.198, 1.189,\n",
    "]\n",
    "\n",
    "def find_pt_bin(pt):\n",
    "  ipt = np.digitize((pt,), pt_bins[1:])[0]  # skip lowest edge\n",
    "  ipt = np.clip(ipt, 0, len(pt_bins)-2)\n",
    "  return ipt\n",
    "\n",
    "def find_emtf_road_quality(ipt):\n",
    "  best_ipt = find_pt_bin(0.)\n",
    "  return best_ipt - np.abs(ipt - best_ipt)\n",
    "\n",
    "nvariables = nvariables\n",
    "\n",
    "discr_pt_cut = discr_pt_cut\n",
    "\n",
    "def get_theta_median_from_x(x):\n",
    "  assert(x.shape[0] == nvariables)\n",
    "  theta_median = x[-1] # last variable\n",
    "  theta_median = (theta_median * 83) + 3\n",
    "  return theta_median.astype(np.int32)\n",
    "\n",
    "def get_zone_from_x(x):\n",
    "  assert(x.shape[0] == nvariables)\n",
    "  zone = x[-2] # second last variable\n",
    "  zone = (zone * 5) + 0\n",
    "  return zone.astype(np.int32)\n",
    "\n",
    "def get_straightness_from_x(x):\n",
    "  assert(x.shape[0] == nvariables)\n",
    "  straightness = x[-3] # third last variable\n",
    "  straightness = (straightness * 4) + 4\n",
    "  return straightness.astype(np.int32)\n",
    "\n",
    "def get_ndof_from_x_mask(x_mask):\n",
    "  assert(x_mask.shape[0] == nlayers)\n",
    "  assert(x_mask.dtype == np.bool)\n",
    "  valid = ~x_mask\n",
    "  return valid.sum()\n",
    "\n",
    "def get_mode_from_x_mask(x_mask):\n",
    "  assert(x_mask.shape[0] == nlayers)\n",
    "  assert(x_mask.dtype == np.bool)\n",
    "  valid = ~x_mask\n",
    "  mode = np.int32(0)\n",
    "  if np.any([valid[0], valid[1], valid[5], valid[9], valid[11]]):   # ME1/1, ME1/2, RE1/2, GE1/1, ME0\n",
    "    mode |= (1<<3)\n",
    "  if np.any([valid[2], valid[6], valid[10]]):  # ME2, RE2, GE2/1\n",
    "    mode |= (1<<2)\n",
    "  if np.any([valid[3], valid[7]]):  # ME3, RE3\n",
    "    mode |= (1<<1)\n",
    "  if np.any([valid[4], valid[8]]):  # ME4, RE4\n",
    "    mode |= (1<<0)\n",
    "\n",
    "  # Apply modified SingleMu requirement\n",
    "  mode_me0 = np.int32(0)\n",
    "  if valid[11]: # ME0\n",
    "    mode_me0 |= (1 << 2)\n",
    "  if valid[0]:  # ME1/1\n",
    "    mode_me0 |= (1 << 1)\n",
    "  if np.any([valid[2], valid[3], valid[4]]):  # ME2, ME3, ME4\n",
    "    mode_me0 |= (1 << 0)\n",
    "  if mode not in (11,13,14,15) and mode_me0 == 7:\n",
    "    mode = 11  # pretend as mode 11\n",
    "  return mode\n",
    "\n",
    "class TrackProducer(object):\n",
    "    def __init__(self):\n",
    "        self.s_min = 0.\n",
    "        self.s_max = 60.\n",
    "        self.s_nbins = 120\n",
    "        self.s_step = (self.s_max - self.s_min)/self.s_nbins\n",
    "        self.s_lut =[ 1.8005,  1.5194,  1.5708,  1.8247,  2.1989,  2.6489,  3.1625,  3.7251,\n",
    "                      4.3240,  4.9595,  5.6337,  6.3424,  7.0590,  7.7485,  8.4050,  9.0398,\n",
    "                      9.6598, 10.2800, 10.9236, 11.6060, 12.3216, 13.0521, 13.7887, 14.5427,\n",
    "                     15.2964, 16.0232, 16.7303, 17.4535, 18.2066, 19.0044, 19.8400, 20.6934,\n",
    "                     21.5215, 22.3143, 23.1066, 23.8221, 24.4586, 25.1335, 25.9083, 26.7333,\n",
    "                     27.5310, 28.2623, 28.9778, 29.7226, 30.5507, 31.4670, 32.4541, 33.5263,\n",
    "                     34.5659, 35.5155, 36.4457, 37.4019, 38.3762, 39.3604, 40.3595, 41.3763,\n",
    "                     42.3333, 43.2434, 44.2686, 45.5962, 47.0878, 48.3783, 49.4891, 50.5445,\n",
    "                     51.4431, 52.2846, 53.1180, 53.9492, 54.7793, 55.6090, 56.4384, 57.2676,\n",
    "                     58.0967, 58.9257, 59.7547, 60.5836, 61.4125, 62.2413, 63.0702, 63.8990,\n",
    "                     64.7278, 65.5566, 66.3854, 67.2142, 68.0430, 68.8718, 69.7006, 70.5293,\n",
    "                     71.3581, 72.1869, 73.0157, 73.8444, 74.6732, 75.5020, 76.3307, 77.1595,\n",
    "                     77.9882, 78.8170, 79.6458, 80.4745, 81.3033, 82.1321, 82.9608, 83.7896,\n",
    "                     84.6183, 85.4471, 86.2759, 87.1046, 87.9334, 88.7621, 89.5909, 90.4197,\n",
    "                     91.2484, 92.0772, 92.9059, 93.7347, 94.5635, 95.3922, 96.2210, 97.0497]\n",
    "        #self.s_lut = np.linspace(self.s_min, self.s_max, num=self.s_nbins+1)[:-1]\n",
    "        self.s_step = np.asarray(self.s_step)\n",
    "        self.s_lut = np.asarray(self.s_lut)\n",
    "    \n",
    "    def get_trigger_pt(self, x, y_meas):\n",
    "        xml_pt = np.abs(1.0/y_meas)\n",
    "        if xml_pt <= 2.:  # do not use the LUT if below 2 GeV\n",
    "            return xml_pt\n",
    "    \n",
    "        def digitize(x, bins=(self.s_nbins, self.s_min, self.s_max)):\n",
    "            x = np.clip(x, bins[1], bins[2]-1e-5)\n",
    "            binx = (x - bins[1]) / (bins[2] - bins[1]) * bins[0]\n",
    "            return binx.astype(np.int32)\n",
    "    \n",
    "        def interpolate(x, x0, x1, y0, y1):\n",
    "            y = (x - x0) / (x1 - x0) * (y1 - y0) + y0\n",
    "            return y\n",
    "    \n",
    "        binx = digitize(xml_pt)\n",
    "        if binx == self.s_nbins-1:  # check boundary\n",
    "            binx -= 1\n",
    "    \n",
    "        x0, x1 = binx * self.s_step, (binx+1) * self.s_step\n",
    "        y0, y1 = self.s_lut[binx], self.s_lut[binx+1]\n",
    "        pt = interpolate(xml_pt, x0, x1, y0, y1)\n",
    "        return pt\n",
    "    \n",
    "    def pass_trigger(self, strg, ndof, mode, theta_median, y_meas, y_discr, discr_pt_cut=14.):\n",
    "        ipt1 = strg\n",
    "        ipt2 = find_pt_bin(y_meas)\n",
    "        quality1 = find_emtf_road_quality(ipt1)\n",
    "        quality2 = find_emtf_road_quality(ipt2)\n",
    "    \n",
    "        if mode in (11,13,14,15) and quality2 <= (quality1+1):\n",
    "            if np.abs(1.0/y_meas) > 14:\n",
    "                trigger = (y_discr > 0.9136) # 98.0% coverage\n",
    "            elif np.abs(1.0/y_meas) > discr_pt_cut:\n",
    "                trigger = (y_discr > 0.7415) # 98.0% coverage\n",
    "            else:\n",
    "                trigger = (y_discr >= 0.)  # True\n",
    "        else:\n",
    "            trigger = (y_discr < 0.)  # False\n",
    "        return trigger\n",
    "  \n",
    "    def run(self, slim_roads, variables, predictions, other_vars):\n",
    "        assert(len(slim_roads) == len(variables))\n",
    "        assert(len(slim_roads) == len(predictions))\n",
    "        assert(len(slim_roads) == len(other_vars))\n",
    "    \n",
    "        tracks = []\n",
    "    \n",
    "        for myroad, myvars, mypreds, myother in zip(slim_roads, variables, predictions, other_vars):\n",
    "            assert(len(myvars.shape) == 1)\n",
    "            x = myvars\n",
    "            x_mask = myother\n",
    "            y_meas = np.asscalar(mypreds[...,0])\n",
    "            y_discr = np.asscalar(mypreds[...,1])\n",
    "      \n",
    "            theta_median = get_theta_median_from_x(x)\n",
    "            zone = get_zone_from_x(x)\n",
    "            strg = get_straightness_from_x(x)\n",
    "            ndof = get_ndof_from_x_mask(x_mask)\n",
    "            mode = get_mode_from_x_mask(x_mask)\n",
    "      \n",
    "            passed = self.pass_trigger(strg, ndof, mode, theta_median, y_meas, y_discr, discr_pt_cut=discr_pt_cut)\n",
    "            xml_pt = np.abs(1.0/y_meas)\n",
    "            pt = self.get_trigger_pt(x, y_meas)\n",
    "      \n",
    "            if passed:\n",
    "                trk_q = np.sign(y_meas)\n",
    "                trk_emtf_phi = myroad.id[4]\n",
    "                trk_emtf_theta = myroad.theta_median\n",
    "                trk = Track(myroad.id, myroad.hits, mode, xml_pt, pt, trk_q, trk_emtf_phi, trk_emtf_theta, ndof, y_discr)\n",
    "                tracks.append(trk)\n",
    "        return tracks\n",
    "\n",
    "mytrigger = TrackProducer()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TestMyTrigger\n",
    "for i in xrange(1,1000):\n",
    "  xml_pt = i * 0.25\n",
    "  x = None\n",
    "  y_meas = 1.0/xml_pt\n",
    "  pt = mytrigger.get_trigger_pt(x, y_meas)\n",
    "  print i, xml_pt, pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Efficiency\n",
    "eff_data = []\n",
    "#MK: because assert dnn_input size test \n",
    "x_test2 = separate_input(x_test)\n",
    "for ievt, (x, x_mask, y_meas, y_discr, y_true) in enumerate(zip(x_test2[0], x_mask_test, y_test_meas[0], y_test_meas[1], y_test_true[0])):\n",
    "  theta_median = get_theta_median_from_x(x)\n",
    "  zone = get_zone_from_x(x)\n",
    "  strg = get_straightness_from_x(x)\n",
    "  ndof = get_ndof_from_x_mask(x_mask)\n",
    "  mode = get_mode_from_x_mask(x_mask)\n",
    "  \n",
    "  passed = mytrigger.pass_trigger(strg, ndof, mode, theta_median, y_meas, y_discr, discr_pt_cut=discr_pt_cut)\n",
    "  xml_pt = np.abs(1.0/y_meas)\n",
    "  pt = mytrigger.get_trigger_pt(x, y_meas)\n",
    "  pt_true = np.abs(1.0/y_true)\n",
    "  \n",
    "  eff_data.append((zone, pt_true, xml_pt, pt, passed, theta_median))\n",
    "  \n",
    "  # Debug\n",
    "  if ievt < 20.:\n",
    "    print ievt, ndof, float(y_discr), float(pt_true), float(xml_pt), float(pt), passed\n",
    "  \n",
    "eff_data = np.asarray(eff_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Efficiency\n",
    "plt.figure()\n",
    "\n",
    "pt = 20\n",
    "color = my_palette[1]\n",
    "gen_passed = eff_data[:, 1] > 30  # index 1 is pt_true\n",
    "passed = gen_passed & (eff_data[:, 3] > pt) & (eff_data[:, 4] == 1)  # index 3 is pt, index 4 is passed\n",
    "\n",
    "denom_hist, edges = np.histogram(eff_data[:, 5][gen_passed], bins=89, range=(0.5,89.5))  # index 5 is theta_median\n",
    "num_hist, edges = np.histogram(eff_data[:, 5][passed], bins=89, range=(0.5,89.5))  # index 1 is pt_true\n",
    "eff_hist = np.true_divide(num_hist, denom_hist)\n",
    "\n",
    "xdata = (edges[1:] + edges[:-1])/2\n",
    "xerr = (edges[1:] - edges[:-1])/2\n",
    "yerr = find_efficiency_errors(denom_hist, num_hist)\n",
    "ydata = eff_hist\n",
    "#print pt, ydata\n",
    "\n",
    "plt.errorbar(xdata, ydata, xerr=xerr, yerr=yerr, color=color, marker=',', capsize=0, lw=1)\n",
    "\n",
    "passed = gen_passed & (eff_data[:, 3] > pt) & (eff_data[:, 4] >= 0)  # index 3 is pt, index 4 is passed\n",
    "num_hist, edges = np.histogram(eff_data[:, 5][passed], bins=89, range=(0.5,89.5))  # index 1 is pt_true\n",
    "eff_hist = np.true_divide(num_hist, denom_hist)\n",
    "yerr = find_efficiency_errors(denom_hist, num_hist)\n",
    "ydata = eff_hist\n",
    "\n",
    "plt.errorbar(xdata, ydata, xerr=xerr, yerr=yerr, color=color, alpha=0.5, marker=',', capsize=0, lw=1)\n",
    "  \n",
    "plt.plot([0,90], [0.9,0.9], ls='dashed', lw=0.5, color='black')\n",
    "plt.xlim(0,90)\n",
    "plt.ylim(0,1.1)\n",
    "plt.xlabel(r'track $\\theta$')\n",
    "plt.ylabel(r'$\\epsilon$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Efficiency\n",
    "eff_pt_bins = (0., 0.5, 1., 1.5, 2., 3., 4., 5., 6., 7., 8., 10., 12., 14., 16., 18., 20., 22., 24., 27., 30., 34., 40., 48., 60., 80., 120.)\n",
    "\n",
    "# MK\n",
    "#pt_list = (10., 20., 30., 40., 50., 60.)\n",
    "pt_list = (15,25)\n",
    "plt.figure()\n",
    "\n",
    "denom_hist, edges = np.histogram(eff_data[:, 1], bins=eff_pt_bins)  # index 1 is pt_true\n",
    "\n",
    "#zone,0; pt_true,1; xml_pt,2; pt,3; passed,4; theta_median,5;\n",
    "\n",
    "for pt, color in zip(pt_list, my_palette):\n",
    "    passed = (eff_data[:, 3] > pt) & (eff_data[:, 4] == 1)  # index 3 is pt, index 4 is passed\n",
    "    num_hist, edges = np.histogram(eff_data[:, 1][passed], bins=eff_pt_bins)  # index 1 is pt_true\n",
    "    eff_hist = np.true_divide(num_hist, denom_hist)\n",
    "    \n",
    "    xdata = (edges[1:] + edges[:-1])/2\n",
    "    xerr = (edges[1:] - edges[:-1])/2\n",
    "    yerr = find_efficiency_errors(denom_hist, num_hist)\n",
    "    ydata = eff_hist\n",
    "    strpt = str(pt)\n",
    "    np.save(model_name_MK+'_eff_xdata'+strpt,xdata)\n",
    "    np.save(model_name_MK+'_eff_xerr'+strpt,xerr)\n",
    "    np.save(model_name_MK+'_eff_yerr'+strpt,yerr)\n",
    "    np.save(model_name_MK+'_eff_ydata'+strpt,ydata)\n",
    "    print pt, ydata\n",
    "    \n",
    "    plt.errorbar(xdata, ydata, xerr=xerr, yerr=yerr, color=color, marker=',', capsize=0, lw=1)\n",
    "\n",
    "plt.plot([0,120], [0.9,0.9], ls='dashed', lw=0.5, color='black')\n",
    "plt.xlim(0,120)\n",
    "plt.ylim(0,1.1)\n",
    "plt.xlabel(r'true $p_{T}$ [GeV]')\n",
    "plt.ylabel(r'$\\epsilon$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find out pT scale factor\n",
    "\n",
    "nbinsx = 120\n",
    "xedges = np.linspace(0, 60, num=nbinsx+1)  # 0.5GeV step size\n",
    "\n",
    "xxx = np.zeros((4,nbinsx), dtype=np.float32)\n",
    "\n",
    "#zone,0; pt_true,1; xml_pt,2; pt(trigger),3; passed,4; theta_median,5;\n",
    "for j in xrange(4):  # j = zone0-1, zone2-4, zone5-6, all zones\n",
    "    if j == 0:\n",
    "        eff_data_tmp = np.logical_or(eff_data[:,0]==0, eff_data[:,0]==1)\n",
    "    elif j == 1:\n",
    "        eff_data_tmp = np.logical_or(eff_data[:,0]==2, eff_data[:,0]==3, eff_data[:,0]==4)\n",
    "    elif j == 2:\n",
    "        eff_data_tmp = np.logical_or(eff_data[:,0]==5, eff_data[:,0]==6)\n",
    "    elif j == 3:\n",
    "        eff_data_tmp = (eff_data[:,0] >= 0)\n",
    "  \n",
    "    xx = eff_data[:,1][eff_data_tmp]  # pt_true\n",
    "    yy = eff_data[:,2][eff_data_tmp]  # xml_pt\n",
    "    zz = eff_data[:,4][eff_data_tmp]  # discr_passed\n",
    "    \n",
    "    ind = np.digitize(xx, xedges[1:])\n",
    "    \n",
    "\n",
    "    for i in xrange(nbinsx):  # i = pT in 0.5GeV step\n",
    "        if xedges[i] <= 2:  # ignore below 2 GeV\n",
    "            xxx[j,i] = xedges[i]\n",
    "            continue\n",
    "        \n",
    "        if xedges[i] <= 24:\n",
    "            step = 4  # 2GeV step size\n",
    "        elif xedges[i] <= 32:\n",
    "            step = 8  # 4GeV step size\n",
    "        elif xedges[i] <= 36:\n",
    "            step = 12 # 6GeV step size\n",
    "        else:\n",
    "            step = 16 # 8GeV step size\n",
    "        xx_i = xx[(i <= ind) & (ind <= i+step)]\n",
    "        yy_i = yy[(i <= ind) & (ind <= i+step)]\n",
    "        zz_i = zz[(i <= ind) & (ind <= i+step)]\n",
    "        coverage = 90  \n",
    "        coverage += 1.0 # inefficiency due to fiducial cuts\n",
    "        #coverage += 1.5 # inefficiency due to fiducial cuts\n",
    "        #pct = np.percentile(yy_i, 100-coverage, overwrite_input=True)\n",
    "        \n",
    "        yz_i = np.where(zz_i==0, 0, yy_i) # 0 means it's pileup, then pt_meas is 0; if it's signal it's pt_meas\n",
    "        # 0 crips in here. so pt and 0 ; a lot of pile-up there. fot 20GeV pt bin [0,0,0,0,0,20,21,25] situation\n",
    "        pct = np.percentile(yz_i, 100-coverage, overwrite_input=True)\n",
    "        \n",
    "        xxx[j,i] = pct\n",
    "        \n",
    "        # Debug\n",
    "        if j == 3 and 14 <= xedges[i] <= 30:\n",
    "            print xedges[i], 100. * (zz_i==0).sum() / (zz_i>=0).sum()\n",
    "        #print np.mean(xx_i), len(xx_i), pct\n",
    "        #if xedges[i] == 20:\n",
    "        #  print i, coverage, np.percentile(yy_i, [1,2,3,4,5,6,7,8,9,10,11,12], overwrite_input=True)\n",
    "        #  print i, coverage, np.percentile(yy_i[zz_i==1], [1,2,3,4,5,6,7,8,9,10,11,12], overwrite_input=True)\n",
    "\n",
    "#print np.array2string(xxx, separator=', ', precision=4, floatmode='fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "xdata = (xedges[1:] + xedges[:-1])/2\n",
    "#plt.plot(xxx[0,:-16], xdata[:-16]) # 16 step size thing\n",
    "plt.plot(xxx[0,:-16], xdata[:-16])\n",
    "plt.plot(xxx[1,:-16], xdata[:-16])\n",
    "plt.plot(xxx[2,:-16], xdata[:-16])\n",
    "plt.plot(xxx[3,:-16], xdata[:-16])\n",
    "plt.xlabel(r'$p_{T}$ [GeV]')\n",
    "plt.ylabel(r'$p_{T}$ after scale factor [GeV]')\n",
    "\n",
    "from scipy.interpolate import Rbf\n",
    "rbf0 = Rbf(xxx[0,:-16], xedges[:-16-1], smooth = 10.0, function='multiquadric')\n",
    "rbf1 = Rbf(xxx[1,:-16], xedges[:-16-1], smooth = 10.0, function='multiquadric')\n",
    "rbf2 = Rbf(xxx[2,:-16], xedges[:-16-1], smooth = 10.0, function='multiquadric')\n",
    "rbf3 = Rbf(xxx[3,:-16], xedges[:-16-1], smooth = 10.0, function='multiquadric')\n",
    "\n",
    "xdata = xedges[:-1]\n",
    "ydata0 = rbf0(xdata)\n",
    "ydata1 = rbf1(xdata)\n",
    "ydata2 = rbf2(xdata)\n",
    "ydata3 = rbf3(xdata)\n",
    "\n",
    "line0, = plt.plot(xdata, ydata0)\n",
    "line1, = plt.plot(xdata, ydata1)\n",
    "line2, = plt.plot(xdata, ydata2)\n",
    "line3, = plt.plot(xdata, ydata3)\n",
    "\n",
    "print np.array2string(xdata, separator=', ', precision=4, floatmode='fixed')\n",
    "#print np.array2string(ydata0, separator=', ', precision=4, floatmode='fixed')\n",
    "#print np.array2string(ydata1, separator=', ', precision=4, floatmode='fixed')\n",
    "#print np.array2string(ydata2, separator=', ', precision=4, floatmode='fixed')\n",
    "print np.array2string(ydata3, separator=', ', precision=4, floatmode='fixed')\n",
    "\n",
    "def monotoically_increasing(a):\n",
    "  return np.all(a[1:] >= a[:-1], axis=-1)\n",
    "#assert(monotoically_increasing(ydata3[4:]))\n",
    "# y axis trigger pt; x axis true pt\n",
    "plt.legend((line0, line1, line2, line3), ('zone0-1', 'zone2-4', 'zone5-6', 'all zones'), loc='upper left')\n",
    "plt.ylim([0,120])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# to get rates we want 'rates_array'\n",
    "\n",
    "# Rates\n",
    "rates_jobid_offset = 101\n",
    "rates_njobs = 63\n",
    "rates_nevents_per_job = 8000\n",
    "rates_nevents_last_job = 2400\n",
    "rates_nevents = 498400\n",
    "assert(rates_nevents == (rates_njobs-1)*rates_nevents_per_job + rates_nevents_last_job)\n",
    "\n",
    "# Stores highest track pt per event\n",
    "rates_array = np.zeros((rates_njobs-1,rates_nevents_per_job), dtype=np.float32)\n",
    "rates_array_last_job = np.zeros((1,rates_nevents_last_job), dtype=np.float32)\n",
    "\n",
    "\n",
    "#MK: because assert dnn_input size test \n",
    "pu_x_test2 = separate_input(pu_x_test)\n",
    "\n",
    "for ievt, (x, x_mask, y_meas, y_discr, aux) in enumerate(zip(pu_x_test2[0], pu_x_mask_test, pu_y_test_meas[0], pu_y_test_meas[1], pu_aux_test)):\n",
    "    theta_median = get_theta_median_from_x(x)\n",
    "    zone = get_zone_from_x(x)\n",
    "    strg = get_straightness_from_x(x)\n",
    "    ndof = get_ndof_from_x_mask(x_mask)\n",
    "    mode = get_mode_from_x_mask(x_mask)\n",
    "    \n",
    "    passed = mytrigger.pass_trigger(strg, ndof, mode, theta_median, y_meas, y_discr, discr_pt_cut=discr_pt_cut)\n",
    "    #xml_pt = np.abs(1.0/y_meas)\n",
    "    pt = mytrigger.get_trigger_pt(x, y_meas)\n",
    "    #pt_true = np.abs(1.0/y_true)\n",
    "    \n",
    "    (jobid, ievt, highest_part_pt, highest_track_pt) = aux\n",
    "    jobid = int(jobid) - rates_jobid_offset\n",
    "    ievt = int(ievt)\n",
    "    \n",
    "    trk_eta = theta_to_eta_lut[theta_median]\n",
    "    \n",
    "    if jobid < (rates_njobs-1):\n",
    "        if passed and (1.24 <= trk_eta <= 2.4):\n",
    "            rates_array[jobid,ievt] = max(rates_array[jobid,ievt], pt)\n",
    "    else:  # last job\n",
    "        if passed and (1.24 <= trk_eta <= 2.4):\n",
    "            rates_array_last_job[0,ievt] = max(rates_array_last_job[0,ievt], pt)\n",
    "    \n",
    "    # Debug\n",
    "    test_jobs = (31,50,56,60,)\n",
    "    if jobid in test_jobs and passed and pt > 20.:\n",
    "        print \"{0:4.0f} {1:4.0f} {2:7.4f} {3:7.4f}\".format(jobid, ievt, highest_part_pt, highest_track_pt), ndof, pt, y_discr\n",
    "        if pt > 100.:  # wtf?\n",
    "            with np_printoptions(precision=3, suppress=True):\n",
    "                for lay in xrange(nlayers):\n",
    "                    tmp = np.arange(2) * nlayers + lay\n",
    "                    print \"....\", lay, x[tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rates\n",
    "# just reshaping\n",
    "rates = np.concatenate((rates_array.reshape(-1), rates_array_last_job.reshape(-1)))\n",
    "assert(len(rates) == rates_nevents)\n",
    "\n",
    "# If the rates for a particular jobid is zero, assume the job has failed\n",
    "rates_nevents_1 = 0\n",
    "for jobid in xrange(rates_array.shape[0]):\n",
    "    if rates_array[jobid].sum() > 0.:\n",
    "        rates_nevents_1 += rates_nevents_per_job\n",
    "if rates_array_last_job[0].sum() > 0.:\n",
    "    rates_nevents_1 += rates_nevents_last_job\n",
    "logger.info(\"nevents: {0}/{1}\".format(rates_nevents_1, rates_nevents))  # should be half the statistics\n",
    "\n",
    "expected_rates_nevents_1 = 258400\n",
    "if rates_nevents_1 != expected_rates_nevents_1:\n",
    "    logger.warning(\"rates_nevents_1 (which is {0}) != {1}, did some job fail?\".format(rates_nevents_1, expected_rates_nevents_1))\n",
    "# just some unit conversion\n",
    "def conversion_to_kHz(nevents):\n",
    "    orbitFreq = 11246.\n",
    "    nCollBunches = 2808\n",
    "    nZeroBiasEvents = nevents\n",
    "    convFactorToHz = orbitFreq * nCollBunches / nZeroBiasEvents\n",
    "    return (convFactorToHz / 1000.)\n",
    "\n",
    "rates = rates[rates > eps]\n",
    "rates = np.clip(rates, 0., 100.)\n",
    "w = conversion_to_kHz(rates_nevents_1)\n",
    "weights = np.full_like(rates, w)\n",
    "print(type(rates))\n",
    "print(type(weights))\n",
    "np.save(model_name_MK+'_rates',rates)\n",
    "np.save(model_name_MK+'_weights',weights)\n",
    "plt.figure()\n",
    "hist, edges, _ = plt.hist(rates, bins=100, range=(0.,100), cumulative=-1, weights=weights, histtype='stepfilled', facecolor='orange', edgecolor='k', alpha=0.6)\n",
    "\n",
    "xdata = (edges[1:] + edges[:-1])/2\n",
    "xerr = (edges[1:] - edges[:-1])/2\n",
    "ydata = hist\n",
    "sumw2 = (ydata/w)\n",
    "yerr = w*np.sqrt(sumw2)\n",
    "print(type(xdata),type(xerr))\n",
    "print(type(ydata),type(yerr))\n",
    "np.save(model_name_MK+'_rates_xdata',xdata)\n",
    "np.save(model_name_MK+'_rates_xerr',xerr)\n",
    "np.save(model_name_MK+'_rates_ydata',ydata)\n",
    "np.save(model_name_MK+'_rates_yerr',yerr)\n",
    "plt.errorbar(xdata, ydata, xerr=xerr, yerr=yerr, color='#333333', ecolor='#333333', fmt='none', capsize=0, lw=1)\n",
    "plt.xlabel(r'$p_{T}$ threshold [GeV]')\n",
    "plt.ylabel(r'Trigger rate [kHz]')\n",
    "plt.xlim(0,30)\n",
    "plt.ylim(1e-1,1e4)\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "logger.info(\"Rates in kHz at 18/19/20/21/22 GeV: {0}, {1}, {2}, {3}, {4}\".format(hist[18], hist[19], hist[20], hist[21], hist[22]))\n",
    "print np.array2string(hist, separator=', ', precision=4, floatmode='fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old rates\n",
    "old_hist = [7.7367e+03, 7.7367e+03, 7.7367e+03, 3.0139e+03, 1.3394e+03, 7.0830e+02,\n",
    "  4.3146e+02, 2.8350e+02, 1.9920e+02, 1.4260e+02, 1.0817e+02, 8.1777e+01,\n",
    "  6.2449e+01, 4.8319e+01, 3.9061e+01, 2.9235e+01, 1.9896e+01, 1.3156e+01,\n",
    "  8.9329e+00, 7.0651e+00, 6.7403e+00, 6.2531e+00, 5.3598e+00, 5.0349e+00,\n",
    "  4.7101e+00, 3.9792e+00, 3.6544e+00, 3.3296e+00, 3.1671e+00, 3.0047e+00,\n",
    "  2.8423e+00, 2.5987e+00, 2.5175e+00, 2.5175e+00, 2.1926e+00, 2.1926e+00,\n",
    "  2.1114e+00, 2.0302e+00, 1.8678e+00, 1.7054e+00, 1.7054e+00, 1.6242e+00,\n",
    "  1.6242e+00, 1.6242e+00, 1.4618e+00, 1.4618e+00, 1.4618e+00, 1.2993e+00,\n",
    "  1.2993e+00, 1.2993e+00, 1.2993e+00, 1.2993e+00, 1.1369e+00, 1.0557e+00,\n",
    "  9.7450e-01, 9.7450e-01, 8.9329e-01, 8.9329e-01, 8.9329e-01, 8.9329e-01,\n",
    "  8.9329e-01, 8.9329e-01, 8.1209e-01, 7.3088e-01, 6.4967e-01, 6.4967e-01,\n",
    "  5.6846e-01, 5.6846e-01, 5.6846e-01, 5.6846e-01, 5.6846e-01, 5.6846e-01,\n",
    "  5.6846e-01, 5.6846e-01, 5.6846e-01, 5.6846e-01, 5.6846e-01, 5.6846e-01,\n",
    "  5.6846e-01, 5.6846e-01, 5.6846e-01, 5.6846e-01, 5.6846e-01, 4.8725e-01,\n",
    "  4.8725e-01, 4.8725e-01, 4.8725e-01, 4.8725e-01, 4.8725e-01, 4.8725e-01,\n",
    "  4.8725e-01, 4.8725e-01, 4.8725e-01, 4.8725e-01, 4.8725e-01, 4.8725e-01,\n",
    "  4.8725e-01, 4.8725e-01, 4.8725e-01, 4.8725e-01]\n",
    "old_hist = np.array(old_hist, dtype=np.float32)\n",
    "\n",
    "plt.figure()\n",
    "centers = (edges[1:] + edges[:-1])/2\n",
    "plt.hist(centers, weights=old_hist, bins=edges, histtype='step', color='k', lw=1.5)\n",
    "plt.hist(centers, weights=hist, bins=edges, histtype='step', color='orange', lw=1.5)\n",
    "plt.xlabel(r'$p_{T}$ threshold [GeV]')\n",
    "plt.ylabel(r'Trigger rate [kHz]')\n",
    "plt.xlim(0,100)\n",
    "plt.ylim(1e-1,1e4)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "# 2018-10-16\n",
    "\n",
    "\"\"\"\n",
    "[INFO    ] Done training. Time elapsed: 2:04:54.658612 sec\n",
    "[INFO    ] Epoch 300/300 - loss: 0.137361058068 - regr_loss: 2.40064452563 - discr_loss: 0.0173288300487 - val_loss: 0.135927766511 - val_regr_loss: 2.37786404684 - val_discr_loss: 0.0170345622495\n",
    "\"\"\"\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(format=\"png\", data=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# from https://github.com/keras-team/keras/issues/4843\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.initializers import glorot_uniform, zero\n",
    "\n",
    "\n",
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "x = K.placeholder(name=\"x\", shape=(None, input_dim))\n",
    "ytrue = K.placeholder(name=\"y\", shape=(None, output_dim))\n",
    "\n",
    "hidden_dim = 128\n",
    "W1 = K.variable(glorot_uniform()([input_dim, hidden_dim]))\n",
    "b1 = K.variable(zero()((hidden_dim,)))\n",
    "W2 = K.variable(glorot_uniform()([hidden_dim, output_dim]))\n",
    "b2 = K.variable(zero()((output_dim,)))\n",
    "params = [W1, b1, W2, b2]\n",
    "\n",
    "\n",
    "hidden = K.sigmoid(K.dot(x, W1)+b1)\n",
    "ypred = K.softmax(K.dot(hidden, W2)+b2)\n",
    "\n",
    "\n",
    "loss = K.mean(K.categorical_crossentropy(ytrue, ypred),axis=None)\n",
    "\n",
    "accuracy = categorical_accuracy(ytrue, ypred)\n",
    "\n",
    "opt = Adam()\n",
    "updates = opt.get_updates(params, [], loss, )\n",
    "train = K.function([x, ytrue],[loss, accuracy],updates=updates)\n",
    "\n",
    "test = K.function([x, ytrue], [loss, accuracy])\n",
    "\n",
    "((xtrain, ytrain),(xtest, ytest)) = mnist.load_data()\n",
    "(xtrain, xtest) = [x.reshape((-1, input_dim))/255.0 for x in (xtrain, xtest)]\n",
    "(ytrain, ytest) = [to_categorical(y, output_dim) for y in (ytrain, ytest)]\n",
    "for epoch in range(1000):\n",
    "\tloss, accuracy = train([xtrain, ytrain])\n",
    "\ttest_loss, test_accuracy = test([xtest, ytest])\n",
    "\tprint(\"Epoch: {}, Train Loss: {}, Train Accuracy: {}, Test Loss: {}, Test Accuracy: {}\".format(\n",
    "\t\tepoch, loss, accuracy, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "  import nn_encode\n",
    "  reload(nn_encode)\n",
    "  import nn_data\n",
    "  reload(nn_data)\n",
    "  from nn_encode import Encoder\n",
    "  from nn_data import muon_data_split\n",
    "\n",
    "  adjust_scale = 0\n",
    "  reg_pt_scale = 1.0\n",
    "  correct_for_eta = True\n",
    "  \n",
    "  x_train, x_test, y_train, y_test, w_train, w_test, x_mask_train, x_mask_test = \\\n",
    "    muon_data_split(infile_muon, adjust_scale=adjust_scale, reg_pt_scale=reg_pt_scale, test_size=0.5, correct_for_eta=correct_for_eta)\n",
    "\n",
    "  if not isinstance(y_train, list):\n",
    "    y_train = [y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  print x_train.shape, y_train[0].shape, x_mask_train.shape\n",
    "  #print np.mean(y_train[0]), np.std(y_train[0]), np.percentile(y_train[0], [2,98])\n",
    "  \n",
    "  fig, axs = plt.subplots(80/4, 4, figsize=(4*4,4*80/4), tight_layout=True)\n",
    "\n",
    "  for i in xrange(x_train.shape[1]):\n",
    "    lay = (i % nlayers)\n",
    "    mask = x_mask_train[...,lay].copy()\n",
    "    if i >= (nlayers*6):\n",
    "      mask *= False\n",
    "    \n",
    "    valid = ~mask\n",
    "    x_i = x_train[valid,i]\n",
    "    y_i = y_train[0][valid]/reg_pt_scale\n",
    "\n",
    "    xmin, xmax = -2, 2\n",
    "    ymin, ymax = -0.6, 0.6\n",
    "    if (nlayers) <= i < (nlayers*2):\n",
    "      xmin, xmax = -3, 3\n",
    "    if adjust_scale == 0:\n",
    "      _range = None\n",
    "    else:\n",
    "      _range = [[xmin, xmax], [ymin, ymax]]\n",
    "    \n",
    "    hist = axs[(i/4, i%4)].hist2d(x_i, y_i, bins=40, range=_range, cmap=plt.cm.viridis)\n",
    "    if x_i.size > 0:\n",
    "      print i, x_i.size, np.mean(x_i), np.std(x_i), np.percentile(x_i, [2,98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  from sklearn.linear_model import LinearRegression\n",
    "  from sklearn.covariance import EmpiricalCovariance, MinCovDet\n",
    "\n",
    "  print x_train.shape, y_train[0].shape, x_mask_train.shape\n",
    "\n",
    "  #fig, axs = plt.subplots(80/4, 4, figsize=(4*4,4*80/4), tight_layout=True)\n",
    "  \n",
    "  coefs = np.ones((nlayers * 7) + 3)\n",
    "  \n",
    "  y_train_stdev = np.std(y_train[0]/reg_pt_scale)\n",
    "\n",
    "  for i in xrange(x_train.shape[1]):\n",
    "    lay = (i % nlayers)\n",
    "    mask = x_mask_train[...,lay].copy()\n",
    "    if i >= (nlayers*6):\n",
    "      mask *= False\n",
    "    \n",
    "    valid = ~mask\n",
    "    valid = valid & (np.abs(1.0/y_train[0]) < discr_pt_cut/reg_pt_scale)  # skip high pT part\n",
    "    x_i = x_train[valid,i].copy()\n",
    "    y_i = (y_train[0][valid]/reg_pt_scale).copy()\n",
    "    assert(np.isfinite(x_i).all())\n",
    "    \n",
    "    nentries_test = 120000\n",
    "    x_i = x_i[:nentries_test]\n",
    "    y_i = y_i[:nentries_test]\n",
    "    y_i /= y_train_stdev\n",
    "    #y_i /= (1.0/np.sqrt(12))  # stdev: (b-a)/sqrt(12)\n",
    "    \n",
    "    if x_i.size > 0 and np.std(x_i) > 0.:\n",
    "      coef = 1.0\n",
    "      \n",
    "      # x_phi\n",
    "      if (i < nlayers):\n",
    "        mcd = MinCovDet(assume_centered=True).fit(np.column_stack((x_i,y_i)))\n",
    "        coef = mcd.covariance_[0,1] / mcd.covariance_[0,0]  # Cov[x,y]/Var[x]\n",
    "        print i, coef, np.std(x_i), np.std(x_i * coef), np.std(y_i)\n",
    "        \n",
    "        #lr = LinearRegression(fit_intercept=False).fit(x_i[:,np.newaxis], y_i)\n",
    "        #coef = lr.coef_[0]\n",
    "        #print i, coef, np.std(x_i), np.std(x_i * coef), np.std(y_i)\n",
    "      \n",
    "      # x_theta\n",
    "      elif (nlayers) <= i < (nlayers*2):\n",
    "        coef = 1.0/np.std(x_i)\n",
    "        print i, coef, np.std(x_i), np.std(x_i * coef), np.std(y_i)\n",
    "      \n",
    "      # x_bend\n",
    "      elif (nlayers*2) <= i < (nlayers*3):\n",
    "        if lay in (0,1,2,3,4) or lay in (9,10,11,):  # ME1/1, ME1/2, ME2, ME3, ME4, GE1/1, GE2/1, ME0\n",
    "          mcd = MinCovDet(assume_centered=True).fit(np.column_stack((x_i,y_i)))\n",
    "          coef = mcd.covariance_[0,1] / mcd.covariance_[0,0]  # Cov[x,y]/Var[x]\n",
    "        elif lay in (5,6):  # RE1, RE2\n",
    "          coef = 1.0/np.std(x_i)\n",
    "        else:  # RE3, RE4\n",
    "          coef = -1.0/np.std(x_i)\n",
    "        print i, coef, np.std(x_i), np.std(x_i * coef), np.std(y_i)\n",
    "      \n",
    "      coefs[i] = coef\n",
    "\n",
    "  print np.array2string(coefs, separator=', ', precision=6, floatmode='fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "  with np.load(infile_muon) as loaded:\n",
    "    the_variables = loaded['variables']\n",
    "    the_parameters = loaded['parameters']\n",
    "\n",
    "  from nn_encode import Encoder\n",
    "  encoder = Encoder(the_variables, the_parameters, adjust_scale=adjust_scale, reg_pt_scale=reg_pt_scale)\n",
    "  x, x_mask, y_pt, y_eta = encoder.get_x(), encoder.get_x_mask(), encoder.y_pt.copy(), encoder.y_eta.copy()\n",
    "\n",
    "  y_pt_cut = (np.abs(1.0/y_pt) > discr_pt_cut/reg_pt_scale)  # select high pT part\n",
    "  x, x_mask, y_pt, y_eta = x[y_pt_cut], x_mask[y_pt_cut], y_pt[y_pt_cut], y_eta[y_pt_cut]\n",
    "  \n",
    "  nentries_test = 120000 * 2\n",
    "  x, x_mask, y_pt, y_eta = x[:nentries_test], x_mask[:nentries_test], y_pt[:nentries_test], y_eta[:nentries_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "  fig, axs = plt.subplots(12/4, 4, figsize=(4*4,4*12/4), tight_layout=True)\n",
    "  \n",
    "  for i in xrange(12):\n",
    "    mask = x_mask[...,i].copy()\n",
    "    \n",
    "    valid = ~mask  # valid hits\n",
    "    \n",
    "    denom_hist, edges = np.histogram(np.abs(y_eta), bins=70, range=(1.1,2.5))\n",
    "    num_hist, edges = np.histogram(np.abs(y_eta)[valid], bins=70, range=(1.1,2.5))\n",
    "    eff_hist = np.true_divide(num_hist, denom_hist)\n",
    "    \n",
    "    xdata = (edges[1:] + edges[:-1])/2\n",
    "    ydata = eff_hist\n",
    "    \n",
    "    xmin, xmax = 1.2, 2.5\n",
    "    ymin, ymax = 0, 1.05\n",
    "    \n",
    "    axs[i/4,i%4].errorbar(xdata, ydata, color='b', marker=',', capsize=0, lw=1)\n",
    "    for x in [1.24, 1.55, 1.7, 1.8, 1.98, 2.15, 2.4]:  # vertical lines\n",
    "      axs[i/4,i%4].plot([x,x], [ymin,ymax], '--', color='grey')\n",
    "    for y in [0.95]:  # horizontal lines\n",
    "      axs[i/4,i%4].plot([xmin,xmax], [y,y], '--', color='grey')\n",
    "    axs[i/4,i%4].set_xlim(xmin,xmax)\n",
    "    axs[i/4,i%4].set_ylim(ymin,ymax)\n",
    "  \n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  # Check loss functions\n",
    "  from keras.losses import mean_squared_error, mean_absolute_error\n",
    "  \n",
    "  def huber_loss(y_true, y_pred, delta=1.345):\n",
    "    x = K.abs(y_true - y_pred)\n",
    "    squared_loss = 0.5*K.square(x)\n",
    "    absolute_loss = delta * (x - 0.5*delta)\n",
    "    xx = tf.where(x < delta, squared_loss, absolute_loss)  # needed for tensorflow\n",
    "    return K.mean(xx, axis=-1)\n",
    "  \n",
    "  def asymmetric_huber_loss(y_true, y_pred, delta=1.345):\n",
    "    x = K.abs(y_true - y_pred)\n",
    "    squared_loss = 0.5*K.square(x)\n",
    "    absolute_loss = delta * (x - 0.5*delta)\n",
    "    x2 = K.abs(y_true) - K.abs(y_pred)  # x2 >= 0: underprediction of 1/pT -> overprediction of pT\n",
    "    xx = tf.where(tf.logical_or(x < delta, x2 >= 0), squared_loss, absolute_loss)  # needed for tensorflow\n",
    "    return K.mean(xx, axis=-1)\n",
    "\n",
    "  nentries_test = x_test.shape[0]//100\n",
    "\n",
    "  # Prepare y_test_true, y_test_meas\n",
    "  y_test_true = y_test\n",
    "  if isinstance(y_test_true, list):\n",
    "    y_test_true = y_test_true[0]\n",
    "  y_test_true = y_test_true[:nentries_test].copy()\n",
    "  y_test_true = y_test_true.reshape(-1)\n",
    "  #y_test_true /= reg_pt_scale\n",
    "\n",
    "  y_test_meas = loaded_model.predict(x_test[:nentries_test], batch_size=4096)\n",
    "  if isinstance(y_test_meas, list):\n",
    "    y_test_meas = y_test_meas[0]\n",
    "  y_test_meas = y_test_meas.reshape(-1)\n",
    "  #y_test_meas /= reg_pt_scale\n",
    "  \n",
    "  sess = K.get_session()\n",
    "  diff = y_test_true - y_test_meas\n",
    "  mask = np.abs(y_test_true) - np.abs(y_test_meas) > 0.\n",
    "  \n",
    "  loss1 = mean_squared_error(y_test_true[:,np.newaxis], y_test_meas[:,np.newaxis]).eval(session=sess)\n",
    "  loss2 = mean_absolute_error(y_test_true[:,np.newaxis], y_test_meas[:,np.newaxis]).eval(session=sess)\n",
    "  loss3 = huber_loss(y_test_true[:,np.newaxis], y_test_meas[:,np.newaxis]).eval(session=sess)\n",
    "  loss4 = asymmetric_huber_loss(y_test_true[:,np.newaxis], y_test_meas[:,np.newaxis]).eval(session=sess)\n",
    "  \n",
    "  plt.figure()\n",
    "  #plt.scatter(diff, loss1, c='r', s=2, edgecolors='none')\n",
    "  #plt.scatter(diff, loss2, c='g', s=2, edgecolors='none')\n",
    "  #plt.scatter(diff, loss3, c='b', s=2, edgecolors='none')\n",
    "  plt.scatter(diff[mask], loss4[mask], c='magenta', s=2, edgecolors='none')\n",
    "  plt.scatter(diff[~mask], loss4[~mask], c='cyan', s=2, edgecolors='none')\n",
    "  #plt.legend(['mse', 'mae', 'huber', 'asym huber #1', 'asym huber #2'])\n",
    "  plt.xlim(-5,5)\n",
    "  plt.ylim(-1,11)\n",
    "  plt.show()\n",
    "  \n",
    "  print y_test_true.shape, y_test_true, y_test_meas, diff, np.percentile(diff, [25,50,75], overwrite_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "  # Tensorflow Interface for CMSSW\n",
    "  # https://github.com/riga/CMSSW-DNN#keras\n",
    "  \n",
    "  import tensorflow as tf\n",
    "  #sess = tf.Session()\n",
    "\n",
    "  from keras import backend as K\n",
    "  #K.set_session(sess)\n",
    "  sess = K.get_session()\n",
    "\n",
    "  # save at as a constant graph\n",
    "  ## names found with: [node.op.name for node in loaded_model.outputs]\n",
    "  ## to get all nodes: [n.name for n in tf.get_default_graph().as_graph_def().node]\n",
    "  #outputs = [u'regr/BiasAdd', u'discr/Sigmoid']\n",
    "  outputs = [u'dense_7_1/BiasAdd']\n",
    "  constant_graph = tf.graph_util.convert_variables_to_constants(\n",
    "      sess, sess.graph.as_graph_def(), outputs)\n",
    "  tf.train.write_graph(constant_graph, \"/tmp/jiafu\", \"constantgraph.pb\", as_text=False)\n",
    "\n",
    "  # save it as a SavedModel\n",
    "  builder = tf.saved_model.builder.SavedModelBuilder(\"/tmp/jiafu/simplegraph\")\n",
    "  builder.add_meta_graph_and_variables(sess, [tf.saved_model.tag_constants.SERVING])\n",
    "  builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
