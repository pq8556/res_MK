{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Using cmssw CMSSW_10_1_7\n",
      "[INFO    ] Using numpy 1.14.1\n",
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc630/external/py2-pippkgs_depscipy/3.0-omkpbe5/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "[INFO    ] Using tensorflow 1.5.0\n",
      "Using TensorFlow backend.\n",
      "[INFO    ] Using keras 2.1.4\n",
      "[INFO    ] .. list devices: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456)]\n",
      "[INFO    ] Using scipy 1.0.0\n",
      "[INFO    ] Using sklearn 0.19.2\n"
     ]
    }
   ],
   "source": [
    "from nn_globals import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_logging import getLogger\n",
    "logger = getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_data(filename):\n",
    "  try:\n",
    "    logger.info('Loading cnn data from {0} ...'.format(filename))\n",
    "    loaded = np.load(filename)\n",
    "    the_image_pixels   = loaded['image_pixels']\n",
    "    the_image_channels = loaded['image_channels']\n",
    "    the_labels         = loaded['labels']\n",
    "    the_parameters     = loaded['parameters']  # q/pt, phi, eta, best_sector\n",
    "    logger.info('Loaded the images with shape {0},{1}'.format(the_image_pixels.shape, the_image_channels.shape))\n",
    "    logger.info('Loaded the labels with shape {0}'.format(the_labels.shape))\n",
    "    logger.info('Loaded the parameters with shape {0}'.format(the_parameters.shape))\n",
    "  except:\n",
    "    logger.error('Failed to load data from file: {0}'.format(filename))\n",
    "\n",
    "  assert(the_image_pixels.shape[0] == the_image_channels.shape[0])\n",
    "  assert(the_image_pixels.shape[0] == the_labels.shape[0])\n",
    "  assert(the_image_pixels.shape[0] == the_parameters.shape[0])\n",
    "\n",
    "  return the_image_pixels, the_image_channels, the_labels, the_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Loading cnn data from ../test7/histos_tbe.17.npz ...\n",
      "[INFO    ] Loaded the images with shape (3535956, 50, 2),(3535956, 50, 3)\n",
      "[INFO    ] Loaded the labels with shape (3535956, 3)\n",
      "[INFO    ] Loaded the parameters with shape (3535956, 3)\n"
     ]
    }
   ],
   "source": [
    "image_pixels, image_channels, labels, parameters = cnn_data(infile_images)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "test_size = 0.4\n",
    "shuffle = False\n",
    "\n",
    "(image_pixels_train, image_pixels_test, image_channels_train, image_channels_test, labels_train, labels_test, parameters_train, parameters_test) = train_test_split(image_pixels, image_channels, labels, parameters, test_size=test_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "  nentries = 100000\n",
    "  (image_pixels_train, image_pixels_test, image_channels_train, image_channels_test, labels_train, labels_test, parameters_train, parameters_test) = train_test_split(image_pixels[:nentries], image_channels[:nentries], labels[:nentries], parameters[:nentries], test_size=test_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imaging(pixels, channels, superstrip_size):\n",
    "  zone_size = 7\n",
    "  m_size = 11\n",
    "  n_size = 5040 // superstrip_size\n",
    "  chn_size = 3\n",
    "  image = np.zeros((m_size*zone_size, n_size, chn_size), dtype=np.float32)\n",
    "  mask = (pixels[:,0] != -99)\n",
    "  image[pixels[mask,0], pixels[mask,1]] = channels[mask]\n",
    "  return image\n",
    "\n",
    "def labeling(labels):\n",
    "  pt_size = 21\n",
    "  phi_size = 128\n",
    "  eta_size = 7\n",
    "  image = np.zeros((pt_size, phi_size, eta_size), dtype=np.float32)\n",
    "  image[labels[0], labels[1], labels[2]] = 1\n",
    "  return image\n",
    "\n",
    "def draw(image, label):\n",
    "  aspect = 'auto'\n",
    "  extent = (0,image.shape[1],0,image.shape[0])\n",
    "  #plt.imshow(image[:,:,0], cmap='viridis', interpolation='none', extent=extent, aspect=aspect)\n",
    "  #plt.show()\n",
    "  #plt.imshow(image[:,:,1], cmap='viridis', interpolation='none', extent=extent, aspect=aspect)\n",
    "  #plt.show()\n",
    "  #plt.imshow(image[:,:,2], cmap='viridis', interpolation='none', extent=extent, aspect=aspect)\n",
    "  #plt.show()\n",
    "  image_2d = np.max(image, axis=-1)\n",
    "  image_2d[np.nonzero(image_2d)] = 1\n",
    "  plt.imshow(image_2d, cmap='viridis', interpolation='none', origin='lower', extent=extent, aspect=aspect)\n",
    "  for y in [11,22,33,44,55,66]:\n",
    "    plt.axhline(y=y,linewidth=1, color='w', alpha=0.4)\n",
    "  plt.show()\n",
    "  print np.where(image_2d)\n",
    "  label_2d = np.max(label, axis=-1)\n",
    "  #label_2d[np.nonzero(label_2d)] = 1\n",
    "  #plt.imshow(label_2d, cmap='viridis', interpolation='none', origin='lower')\n",
    "  #plt.show()\n",
    "  print np.where(label_2d), label_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "superstrip_size = 16\n",
    "n_rows = 7 * 11\n",
    "n_columns = 5040 // superstrip_size\n",
    "n_channels = 3\n",
    "n_classes = 21\n",
    "dropout = 0.2\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image_fn(pixels, channels):\n",
    "  n = pixels.shape[0]\n",
    "  assert(pixels.shape == (n,2))\n",
    "  assert(channels.shape == (n,n_channels))\n",
    "\n",
    "  bad_pixel = -99\n",
    "  mask = tf.not_equal(pixels[:,0], bad_pixel)\n",
    "  \n",
    "  indices = tf.boolean_mask(pixels, mask)\n",
    "  updates = tf.boolean_mask(channels, mask)\n",
    "  image_shape = (n_rows, n_columns, n_channels)\n",
    "  image = tf.scatter_nd(indices, updates, image_shape)\n",
    "  return image\n",
    "\n",
    "def parse_label_fn(labels):\n",
    "  assert(labels.shape == (3,))\n",
    "  lab = labels[:1]\n",
    "  return lab\n",
    "\n",
    "def get_train_input_fn_and_hook():\n",
    "  feed_fn_hook = tf.train.FeedFnHook(feed_fn=None)\n",
    "  \n",
    "  def input_fn():\n",
    "    with tf.name_scope('train_data'):\n",
    "      get_shape_ph = lambda x: [None] + list(x[1:])\n",
    "      image_pixels_ph      = tf.placeholder(image_pixels_train.dtype, get_shape_ph(image_pixels_train.shape))\n",
    "      image_channels_ph    = tf.placeholder(image_channels_train.dtype, get_shape_ph(image_channels_train.shape))\n",
    "      labels_ph            = tf.placeholder(labels_train.dtype, get_shape_ph(labels_train.shape))\n",
    "      parameters_ph        = tf.placeholder(parameters_train.dtype, get_shape_ph(parameters_train.shape))\n",
    "      feed_dict            = {image_pixels_ph: image_pixels_train, image_channels_ph: image_channels_train, labels_ph: labels_train}\n",
    "      feed_fn_hook.feed_fn = lambda: feed_dict\n",
    "\n",
    "      dataset1 = tf.data.Dataset.from_tensor_slices((image_pixels_ph, image_channels_ph))\n",
    "      dataset1 = dataset1.map(map_func=parse_image_fn)\n",
    "      dataset2 = tf.data.Dataset.from_tensor_slices((labels_ph))\n",
    "      dataset2 = dataset2.map(map_func=parse_label_fn)\n",
    "      dataset = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "      print(dataset.output_types)\n",
    "      print(dataset.output_shapes)\n",
    "\n",
    "      batch_size = 1\n",
    "      shuffle_buffer_size = batch_size * 100\n",
    "      prefetch_buffer_size = 1\n",
    "      num_epochs = 10\n",
    "\n",
    "      #dataset = dataset.shuffle(buffer_size=shuffle_buffer_size)\n",
    "      dataset = dataset.batch(batch_size=batch_size)\n",
    "      #dataset = dataset.prefetch(buffer_size=prefetch_buffer_size)\n",
    "      #dataset = dataset.repeat(num_epochs)\n",
    "      return dataset\n",
    "  return input_fn, feed_fn_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "\n",
    "sanity_check = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if sanity_check:\n",
    "  input_fn, feed_fn_hook = get_train_input_fn_and_hook()\n",
    "  result = input_fn()\n",
    "  feed_dict = feed_fn_hook.feed_fn()\n",
    "  #sess.run(tf.global_variables_initializer())\n",
    "  \n",
    "  iterator = result.make_initializable_iterator()\n",
    "  sess.run(iterator.initializer, feed_dict=feed_dict)\n",
    "  \n",
    "  next_element = iterator.get_next()\n",
    "\n",
    "  #print(sess.run(next_element))\n",
    "  #print(sess.run(next_element))\n",
    "  #print(sess.run(next_element))\n",
    "  #print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sanity_check:\n",
    "  import matplotlib as mpl\n",
    "  mpl.rcParams['figure.figsize'] = (10,5)\n",
    "  #mpl.rcParams['axes.labelpad'] = 0\n",
    "  #mpl.rcParams['axes.labelsize'] = 0\n",
    "  #mpl.rcParams['xtick.labelsize'] = 0\n",
    "  #mpl.rcParams['ytick.labelsize'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sanity_check:\n",
    "  image, label = sess.run(next_element)\n",
    "  draw(image[0], label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sanity_check:\n",
    "  image, label = sess.run(next_element)\n",
    "  draw(image[0], label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sanity_check:\n",
    "  image, label = sess.run(next_element)\n",
    "  draw(image[0], label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sanity_check:\n",
    "  image, label = sess.run(next_element)\n",
    "  draw(image[0], label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sanity_check:\n",
    "  image, label = sess.run(next_element)\n",
    "  draw(image[0], label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sanity_check:\n",
    "  image, label = sess.run(next_element)\n",
    "  draw(image[0], label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(params={}):\n",
    "  \"\"\"Model to recognize digits in the MNIST dataset.\n",
    "  Network structure is equivalent to:\n",
    "  https://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/examples/tutorials/mnist/mnist_deep.py\n",
    "  and\n",
    "  https://github.com/tensorflow/models/blob/master/tutorials/image/mnist/convolutional.py\n",
    "  But uses the tf.keras API.\n",
    "  Args:\n",
    "    data_format: Either 'channels_first' or 'channels_last'. 'channels_first' is\n",
    "      typically faster on GPUs while 'channels_last' is typically faster on\n",
    "      CPUs. See\n",
    "      https://www.tensorflow.org/performance/performance_guide#data_formats\n",
    "  Returns:\n",
    "    A tf.keras.Model.\n",
    "  \"\"\"\n",
    "  \n",
    "  data_format = params.get('data_format', 'channels_last')\n",
    "  n_rows = params.get('n_rows', 28)\n",
    "  n_columns = params.get('n_columns', 28)\n",
    "  n_channels = params.get('n_channels', 1)\n",
    "  n_classes = params.get('n_classes', 10)\n",
    "  dropout = params.get('dropout', 0.4)\n",
    "  \n",
    "  if data_format == 'channels_first':\n",
    "    input_shape = [n_channels, n_rows, n_columns]\n",
    "  else:\n",
    "    assert data_format == 'channels_last'\n",
    "    input_shape = [n_rows, n_columns, n_channels]\n",
    "\n",
    "  l = tf.keras.layers\n",
    "      \n",
    "  # The model consists of a sequential chain of layers, so tf.keras.Sequential\n",
    "  # (a subclass of tf.keras.Model) makes for a compact description.\n",
    "  return tf.keras.Sequential(\n",
    "      [\n",
    "          l.Reshape(\n",
    "              target_shape=input_shape,\n",
    "              input_shape=(n_rows * n_columns,)),\n",
    "          l.Conv2D(\n",
    "              32,\n",
    "              5,\n",
    "              padding='same',\n",
    "              data_format=data_format,\n",
    "              activation=tf.nn.relu),\n",
    "          l.MaxPooling2D(\n",
    "              (2, 2), \n",
    "              (2, 2), \n",
    "              padding='same', \n",
    "              data_format=data_format),\n",
    "          l.Conv2D(\n",
    "              64,\n",
    "              5,\n",
    "              padding='same',\n",
    "              data_format=data_format,\n",
    "              activation=tf.nn.relu),\n",
    "          l.MaxPooling2D(\n",
    "              (2, 2), \n",
    "              (2, 2), \n",
    "              padding='same', \n",
    "              data_format=data_format),\n",
    "          l.Flatten(),\n",
    "          l.Dense(1024, activation=tf.nn.relu),\n",
    "          #l.Dropout(dropout),\n",
    "          l.Dense(n_classes),\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "  \"\"\"The model_fn argument for creating an Estimator.\"\"\"\n",
    "  model = create_model(params)\n",
    "  learning_rate = params['learning_rate']\n",
    "  \n",
    "  image = features\n",
    "  if isinstance(image, dict):\n",
    "    image = features['image']\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    #logits = model(image, training=False)\n",
    "    logits = model(image)  # no keyword argument 'training' in tensorflow 1.5\n",
    "    predictions = {\n",
    "        'classes': tf.argmax(logits, axis=1),\n",
    "        'probabilities': tf.nn.softmax(logits),\n",
    "    }\n",
    "    # For mode == ModeKeys.PREDICT: required fields are predictions.\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=tf.estimator.ModeKeys.PREDICT,\n",
    "        predictions=predictions,\n",
    "        export_outputs={\n",
    "            'classify': tf.estimator.export.PredictOutput(predictions)\n",
    "        })\n",
    "  \n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "    # If we are running multi-GPU, we need to wrap the optimizer.\n",
    "    if params.get('multi_gpu'):\n",
    "      optimizer = tf.contrib.estimator.TowerOptimizer(optimizer)\n",
    "\n",
    "    #logits = model(image, training=True)\n",
    "    logits = model(image)  # no keyword argument 'training' in tensorflow 1.5\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    accuracy = tf.metrics.accuracy(\n",
    "        labels=labels, predictions=tf.argmax(logits, axis=1))\n",
    "\n",
    "    # Name tensors to be logged with LoggingTensorHook.\n",
    "    tf.identity(learning_rate, 'learning_rate')\n",
    "    tf.identity(loss, 'cross_entropy')\n",
    "    tf.identity(accuracy[1], name='train_accuracy')\n",
    "\n",
    "    # Save accuracy scalar to Tensorboard output.\n",
    "    tf.summary.scalar('train_accuracy', accuracy[1])\n",
    "\n",
    "    # For mode == ModeKeys.TRAIN: required fields are loss and train_op\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=tf.estimator.ModeKeys.TRAIN,\n",
    "        loss=loss,\n",
    "        train_op=optimizer.minimize(loss, global_step=tf.train.get_or_create_global_step()))\n",
    "  \n",
    "  if mode == tf.estimator.ModeKeys.EVAL:\n",
    "    #logits = model(image, training=False)\n",
    "    logits = model(image)  # no keyword argument 'training' in tensorflow 1.5\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    accuracy = tf.metrics.accuracy(\n",
    "        labels=labels, predictions=tf.argmax(logits, axis=1))\n",
    "    \n",
    "    # Save accuracy scalar to Tensorboard output.\n",
    "    tf.summary.scalar('eval_accuracy', accuracy[1])\n",
    "    \n",
    "    # For mode == ModeKeys.EVAL: required field is loss.\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=tf.estimator.ModeKeys.EVAL,\n",
    "        loss=loss,\n",
    "        eval_metric_ops={'accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFnHook(tf.train.SessionRunHook):\n",
    "  \"\"\"Runs `feed_fn` and sets the `feed_dict` accordingly.\"\"\"\n",
    "\n",
    "  def __init__(self, feed_fn):\n",
    "    \"\"\"Initializes a `FeedFnHook`.\n",
    "    Args:\n",
    "      feed_fn: function that takes no arguments and returns `dict` of `Tensor`\n",
    "        to feed.\n",
    "    \"\"\"\n",
    "    self.feed_fn = feed_fn\n",
    "\n",
    "  def before_run(self, run_context):  # pylint: disable=unused-argument\n",
    "    return tf.train.SessionRunArgs(\n",
    "        fetches=None, feed_dict=self.feed_fn())\n",
    "\n",
    "class _DatasetInitializerHook(tf.train.SessionRunHook):\n",
    "  \"\"\"Creates a SessionRunHook that initializes the passed iterator.\"\"\"\n",
    "\n",
    "  def __init__(self, iterator, feed_fn):\n",
    "    self._iterator = iterator\n",
    "    self.feed_fn = feed_fn\n",
    "\n",
    "  def begin(self):\n",
    "    self._initializer = self._iterator.initializer\n",
    "\n",
    "  def after_create_session(self, session, coord):\n",
    "    del coord\n",
    "    session.run(self._initializer, feed_dict=self.feed_fn())\n",
    "\n",
    "# from tensorflow/python/estimator/estimator.py\n",
    "def _get_features_and_labels_from_input_fn(self, input_fn, mode):\n",
    "  \"\"\"Extracts the `features` and labels from return values of `input_fn`.\"\"\"\n",
    "  result = self._call_input_fn(input_fn, mode)\n",
    "  input_hooks = []\n",
    "  if isinstance(result, tf.data.Dataset):\n",
    "    iterator = result.make_initializable_iterator()\n",
    "    #input_hooks.append(_DatasetInitializerHook(iterator))\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      input_hooks.append(_DatasetInitializerHook(iterator, self.train_input_hook.feed_fn))\n",
    "    else:  # mode == tf.estimator.ModeKeys.EVAL\n",
    "      input_hooks.append(_DatasetInitializerHook(iterator, self.eval_input_hook.feed_fn))\n",
    "    result = iterator.get_next()\n",
    "  if isinstance(result, (list, tuple)):\n",
    "    if len(result) != 2:\n",
    "      raise ValueError(\n",
    "          'input_fn should return (feautures, labels) as a len 2 tuple.')\n",
    "    return result[0], result[1], input_hooks\n",
    "  return result, None, input_hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mnist(flags_obj):\n",
    "  \"\"\"Run MNIST training and eval loop.\n",
    "  Args:\n",
    "    flags_obj: An object containing parsed flag values.\n",
    "  \"\"\"\n",
    "  #model_helpers.apply_clean(flags_obj)\n",
    "  model_function = model_fn\n",
    "  \n",
    "  # Get number of GPUs as defined by the --num_gpus flags and the number of\n",
    "  # GPUs available on the machine.\n",
    "  num_gpus = flags_obj.num_gpus\n",
    "  multi_gpu = num_gpus > 1\n",
    "\n",
    "  if multi_gpu:\n",
    "    # Validate that the batch size can be split into devices.\n",
    "    distribution_utils.per_device_batch_size(flags_obj.batch_size, num_gpus)\n",
    "\n",
    "    # There are two steps required if using multi-GPU: (1) wrap the model_fn,\n",
    "    # and (2) wrap the optimizer. The first happens here, and (2) happens\n",
    "    # in the model_fn itself when the optimizer is defined.\n",
    "    model_function = tf.contrib.estimator.replicate_model_fn(\n",
    "        model_fn, loss_reduction=tf.losses.Reduction.MEAN,\n",
    "        devices=[\"/device:GPU:%d\" % d for d in range(num_gpus)])\n",
    "  \n",
    "  data_format = flags_obj.data_format\n",
    "  \n",
    "  sess_config = tf.ConfigProto(\n",
    "      intra_op_parallelism_threads = 4,\n",
    "      inter_op_parallelism_threads = 4,\n",
    "      allow_soft_placement=True)\n",
    "  \n",
    "  model_config = tf.estimator.RunConfig(\n",
    "      model_dir=flags_obj.model_dir,\n",
    "      tf_random_seed=2023,\n",
    "      session_config=sess_config)\n",
    "  \n",
    "  mnist_classifier = tf.estimator.Estimator(\n",
    "      model_fn=model_function,\n",
    "      model_dir=flags_obj.model_dir,\n",
    "      config=model_config,\n",
    "      params={\n",
    "          'data_format': data_format,\n",
    "          'multi_gpu': multi_gpu,\n",
    "          'n_rows': n_rows,\n",
    "          'n_columns': n_columns,\n",
    "          'n_channels': n_channels,\n",
    "          'n_classes': n_classes,\n",
    "          'dropout': dropout,\n",
    "          'learning_rate': learning_rate,\n",
    "      })\n",
    "  \n",
    "  \n",
    "  # Set up training and evaluation input functions.\n",
    "  def get_train_input_fn_and_hook():\n",
    "    feed_fn_hook = tf.train.FeedFnHook(feed_fn=None)\n",
    "    \n",
    "    def input_fn():\n",
    "      with tf.name_scope('train_data'):\n",
    "        get_shape_ph = lambda x: [None] + list(x[1:])\n",
    "        image_pixels_ph      = tf.placeholder(image_pixels_train.dtype, get_shape_ph(image_pixels_train.shape))\n",
    "        image_channels_ph    = tf.placeholder(image_channels_train.dtype, get_shape_ph(image_channels_train.shape))\n",
    "        labels_ph            = tf.placeholder(labels_train.dtype, get_shape_ph(labels_train.shape))\n",
    "        parameters_ph        = tf.placeholder(parameters_train.dtype, get_shape_ph(parameters_train.shape))\n",
    "        feed_dict            = {image_pixels_ph: image_pixels_train, image_channels_ph: image_channels_train, labels_ph: labels_train}\n",
    "        feed_fn_hook.feed_fn = lambda: feed_dict\n",
    "\n",
    "        dataset1 = tf.data.Dataset.from_tensor_slices((image_pixels_ph, image_channels_ph))\n",
    "        dataset1 = dataset1.map(map_func=parse_image_fn)\n",
    "        dataset2 = tf.data.Dataset.from_tensor_slices((labels_ph))\n",
    "        dataset2 = dataset2.map(map_func=parse_label_fn)\n",
    "        dataset = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "        \n",
    "        # When choosing shuffle buffer sizes, larger sizes result in better\n",
    "        # randomness, while smaller sizes use less memory. MNIST is a small\n",
    "        # enough dataset that we can easily shuffle the full epoch.\n",
    "        #ds = dataset3.cache().shuffle(buffer_size=50000).batch(flags_obj.batch_size)\n",
    "\n",
    "        # Iterate through the dataset a set number (`epochs_between_evals`) of times\n",
    "        # during each training session.\n",
    "        #ds = ds.repeat(flags_obj.epochs_between_evals)\n",
    "        \n",
    "        dataset = dataset.shuffle(buffer_size=flags_obj.shuffle_buffer_size)\n",
    "        dataset = dataset.batch(batch_size=flags_obj.batch_size)\n",
    "        dataset = dataset.prefetch(buffer_size=flags_obj.prefetch_buffer_size)\n",
    "        dataset = dataset.repeat(flags_obj.train_epochs)\n",
    "        return dataset\n",
    "    return input_fn, feed_fn_hook\n",
    "  \n",
    "  def get_eval_input_fn_and_hook():\n",
    "    feed_fn_hook = tf.train.FeedFnHook(feed_fn=None)\n",
    "    \n",
    "    def input_fn():\n",
    "      with tf.name_scope('eval_data'):\n",
    "        get_shape_ph = lambda x: [None] + list(x[1:])\n",
    "        image_pixels_ph      = tf.placeholder(image_pixels_test.dtype, get_shape_ph(image_pixels_test.shape))\n",
    "        image_channels_ph    = tf.placeholder(image_channels_test.dtype, get_shape_ph(image_channels_test.shape))\n",
    "        labels_ph            = tf.placeholder(labels_test.dtype, get_shape_ph(labels_test.shape))\n",
    "        parameters_ph        = tf.placeholder(parameters_test.dtype, get_shape_ph(parameters_test.shape))\n",
    "        feed_dict            = {image_pixels_ph: image_pixels_test, image_channels_ph: image_channels_test, labels_ph: labels_test}\n",
    "        feed_fn_hook.feed_fn = lambda: feed_dict\n",
    "\n",
    "        dataset1 = tf.data.Dataset.from_tensor_slices((image_pixels_ph, image_channels_ph))\n",
    "        dataset1 = dataset1.map(map_func=parse_image_fn)\n",
    "        dataset2 = tf.data.Dataset.from_tensor_slices((labels_ph))\n",
    "        dataset2 = dataset2.map(map_func=parse_label_fn)\n",
    "        dataset = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "        \n",
    "        #ds = dataset3.batch(flags_obj.batch_size).make_one_shot_iterator().get_next()\n",
    "        \n",
    "        dataset = dataset.shuffle(buffer_size=flags_obj.shuffle_buffer_size)\n",
    "        dataset = dataset.batch(batch_size=flags_obj.batch_size)\n",
    "        dataset = dataset.prefetch(buffer_size=flags_obj.prefetch_buffer_size)\n",
    "        dataset = dataset.repeat(flags_obj.train_epochs)\n",
    "        return dataset\n",
    "    return input_fn, feed_fn_hook\n",
    "  \n",
    "  train_input_fn, train_input_hook = get_train_input_fn_and_hook()\n",
    "  \n",
    "  eval_input_fn, eval_input_hook = get_eval_input_fn_and_hook()\n",
    "\n",
    "  # Set up hook that outputs training logs every 100 steps.\n",
    "  train_hooks = get_train_hooks(\n",
    "      flags_obj.hooks, model_dir=flags_obj.model_dir,\n",
    "      batch_size=flags_obj.batch_size)\n",
    "  \n",
    "  eval_hooks = []\n",
    "  \n",
    "  # Patch the function _get_features_and_labels_from_input_fn()\n",
    "  import types\n",
    "  mnist_classifier.train_input_hook = train_input_hook\n",
    "  mnist_classifier.eval_input_hook = eval_input_hook\n",
    "  mnist_classifier._get_features_and_labels_from_input_fn = types.MethodType(_get_features_and_labels_from_input_fn, mnist_classifier)\n",
    "\n",
    "  # Train and evaluate model.\n",
    "  for epoch in range(flags_obj.train_epochs // flags_obj.epochs_between_evals):\n",
    "    mnist_classifier.train(input_fn=train_input_fn, hooks=train_hooks)\n",
    "    eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn, hooks=eval_hooks)\n",
    "    print('Epoch %i Evaluation results:\\n\\t%s\\n' % (epoch, eval_results))\n",
    "\n",
    "    #if model_helpers.past_stop_threshold(flags_obj.stop_threshold,\n",
    "    #                                     eval_results['accuracy']):\n",
    "    #  break\n",
    "\n",
    "  # Export the model\n",
    "  if flags_obj.export_dir is not None:\n",
    "    image = tf.placeholder(tf.float32, [None, n_rows, n_columns])\n",
    "    input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn({\n",
    "        'image': image,\n",
    "    })\n",
    "    mnist_classifier.export_savedmodel(flags_obj.export_dir, input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_hooks(name_list, use_tpu=False, **kwargs):\n",
    "  \"\"\"Factory for getting a list of TensorFlow hooks for training by name.\n",
    "  Args:\n",
    "    name_list: a list of strings to name desired hook classes. Allowed:\n",
    "      LoggingTensorHook, ProfilerHook, ExamplesPerSecondHook, which are defined\n",
    "      as keys in HOOKS\n",
    "    use_tpu: Boolean of whether computation occurs on a TPU. This will disable\n",
    "      hooks altogether.\n",
    "    **kwargs: a dictionary of arguments to the hooks.\n",
    "  Returns:\n",
    "    list of instantiated hooks, ready to be used in a classifier.train call.\n",
    "  Raises:\n",
    "    ValueError: if an unrecognized name is passed.\n",
    "  \"\"\"\n",
    "\n",
    "  if not name_list:\n",
    "    return []\n",
    "\n",
    "  if use_tpu:\n",
    "    tf.logging.warning(\"hooks_helper received name_list `{}`, but a TPU is \"\n",
    "                       \"specified. No hooks will be used.\".format(name_list))\n",
    "    return []\n",
    "\n",
    "  train_hooks = []\n",
    "  for name in name_list:\n",
    "    hook_name = HOOKS.get(name.strip().lower())\n",
    "    if hook_name is None:\n",
    "      raise ValueError('Unrecognized training hook requested: {}'.format(name))\n",
    "    else:\n",
    "      train_hooks.append(hook_name(**kwargs))\n",
    "\n",
    "  return train_hooks\n",
    "\n",
    "\n",
    "def get_logging_tensor_hook(every_n_iter=100, tensors_to_log=None, **kwargs):  # pylint: disable=unused-argument\n",
    "  \"\"\"Function to get LoggingTensorHook.\n",
    "  Args:\n",
    "    every_n_iter: `int`, print the values of `tensors` once every N local\n",
    "      steps taken on the current worker.\n",
    "    tensors_to_log: List of tensor names or dictionary mapping labels to tensor\n",
    "      names. If not set, log _TENSORS_TO_LOG by default.\n",
    "    **kwargs: a dictionary of arguments to LoggingTensorHook.\n",
    "  Returns:\n",
    "    Returns a LoggingTensorHook with a standard set of tensors that will be\n",
    "    printed to stdout.\n",
    "  \"\"\"\n",
    "  if tensors_to_log is None:\n",
    "    tensors_to_log = _TENSORS_TO_LOG\n",
    "\n",
    "  return tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log,\n",
    "      every_n_iter=every_n_iter)\n",
    "\n",
    "\n",
    "def get_profiler_hook(model_dir, save_steps=1000, **kwargs):  # pylint: disable=unused-argument\n",
    "  \"\"\"Function to get ProfilerHook.\n",
    "  Args:\n",
    "    model_dir: The directory to save the profile traces to.\n",
    "    save_steps: `int`, print profile traces every N steps.\n",
    "    **kwargs: a dictionary of arguments to ProfilerHook.\n",
    "  Returns:\n",
    "    Returns a ProfilerHook that writes out timelines that can be loaded into\n",
    "    profiling tools like chrome://tracing.\n",
    "  \"\"\"\n",
    "  return tf.train.ProfilerHook(save_steps=save_steps, output_dir=model_dir)\n",
    "\n",
    "\n",
    "def get_examples_per_second_hook(every_n_steps=100,\n",
    "                                 batch_size=128,\n",
    "                                 warm_steps=5,\n",
    "                                 **kwargs):  # pylint: disable=unused-argument\n",
    "  \"\"\"Function to get ExamplesPerSecondHook.\n",
    "  Args:\n",
    "    every_n_steps: `int`, print current and average examples per second every\n",
    "      N steps.\n",
    "    batch_size: `int`, total batch size used to calculate examples/second from\n",
    "      global time.\n",
    "    warm_steps: skip this number of steps before logging and running average.\n",
    "    **kwargs: a dictionary of arguments to ExamplesPerSecondHook.\n",
    "  Returns:\n",
    "    Returns a ProfilerHook that writes out timelines that can be loaded into\n",
    "    profiling tools like chrome://tracing.\n",
    "  \"\"\"\n",
    "  return hooks.ExamplesPerSecondHook(\n",
    "      batch_size=batch_size, every_n_steps=every_n_steps,\n",
    "      warm_steps=warm_steps, metric_logger=logger.get_benchmark_logger())\n",
    "\n",
    "\n",
    "def get_logging_metric_hook(tensors_to_log=None,\n",
    "                            every_n_secs=600,\n",
    "                            **kwargs):  # pylint: disable=unused-argument\n",
    "  \"\"\"Function to get LoggingMetricHook.\n",
    "  Args:\n",
    "    tensors_to_log: List of tensor names or dictionary mapping labels to tensor\n",
    "      names. If not set, log _TENSORS_TO_LOG by default.\n",
    "    every_n_secs: `int`, the frequency for logging the metric. Default to every\n",
    "      10 mins.\n",
    "  Returns:\n",
    "    Returns a LoggingMetricHook that saves tensor values in a JSON format.\n",
    "  \"\"\"\n",
    "  if tensors_to_log is None:\n",
    "    tensors_to_log = _TENSORS_TO_LOG\n",
    "  return metric_hook.LoggingMetricHook(\n",
    "      tensors=tensors_to_log,\n",
    "      metric_logger=logger.get_benchmark_logger(),\n",
    "      every_n_secs=every_n_secs)\n",
    "\n",
    "\n",
    "_TENSORS_TO_LOG = {\n",
    "    'learning_rate': 'learning_rate',\n",
    "    'cross_entropy': 'cross_entropy',\n",
    "    'train_accuracy': 'train_accuracy',\n",
    "}\n",
    "\n",
    "# A dictionary to map one hook name and its corresponding function\n",
    "HOOKS = {\n",
    "    'loggingtensorhook': get_logging_tensor_hook,\n",
    "    'profilerhook': get_profiler_hook,\n",
    "    'examplespersecondhook': get_examples_per_second_hook,\n",
    "    'loggingmetrichook': get_logging_metric_hook,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import flags\n",
    "\n",
    "def define_mnist_flags():\n",
    "  import functools\n",
    "  help_wrap = functools.partial(flags.text_wrap, length=80, indent=\"\",\n",
    "                                firstline_indent=\"\\n\")\n",
    "  \n",
    "  key_flags = []\n",
    "  \n",
    "  flags.DEFINE_string(\n",
    "        name=\"data_dir\", short_name=\"dd\", default=\"/tmp\",\n",
    "        help=help_wrap(\"The location of the input data.\"))\n",
    "  key_flags.append(\"data_dir\")\n",
    "  \n",
    "  flags.DEFINE_string(\n",
    "        name=\"model_dir\", short_name=\"md\", default=\"/tmp\",\n",
    "        help=help_wrap(\"The location of the model checkpoint files.\"))\n",
    "  key_flags.append(\"model_dir\")\n",
    "  \n",
    "  flags.DEFINE_integer(\n",
    "        name=\"train_epochs\", short_name=\"te\", default=1,\n",
    "        help=help_wrap(\"The number of epochs used to train.\"))\n",
    "  key_flags.append(\"train_epochs\")\n",
    "  \n",
    "  flags.DEFINE_integer(\n",
    "        name=\"epochs_between_evals\", short_name=\"ebe\", default=1,\n",
    "        help=help_wrap(\"The number of training epochs to run between \"\n",
    "                       \"evaluations.\"))\n",
    "  key_flags.append(\"epochs_between_evals\")\n",
    "  \n",
    "  flags.DEFINE_float(\n",
    "        name=\"stop_threshold\", short_name=\"st\",\n",
    "        default=None,\n",
    "        help=help_wrap(\"If passed, training will stop at the earlier of \"\n",
    "                       \"train_epochs and when the evaluation metric is  \"\n",
    "                       \"greater than or equal to stop_threshold.\"))\n",
    "  key_flags.append(\"stop_threshold\")\n",
    "  \n",
    "  flags.DEFINE_integer(\n",
    "        name=\"batch_size\", short_name=\"bs\", default=32,\n",
    "        help=help_wrap(\"Batch size for training and evaluation. When using \"\n",
    "                       \"multiple gpus, this is the global batch size for \"\n",
    "                       \"all devices. For example, if the batch size is 32 \"\n",
    "                       \"and there are 4 GPUs, each GPU will get 8 examples on \"\n",
    "                       \"each step.\"))\n",
    "  key_flags.append(\"batch_size\")\n",
    "  \n",
    "  flags.DEFINE_integer(\n",
    "        name=\"num_gpus\", short_name=\"ng\",\n",
    "        default=1 if tf.test.is_gpu_available() else 0,\n",
    "        help=help_wrap(\n",
    "            \"How many GPUs to use with the DistributionStrategies API. The \"\n",
    "            \"default is 1 if TensorFlow can detect a GPU, and 0 otherwise.\"))\n",
    "  key_flags.append(\"num_gpus\")\n",
    "  \n",
    "  # Construct a pretty summary of hooks.\n",
    "  hook_list_str = (\n",
    "      u\"\\ufeff  Hook:\\n\" + u\"\\n\".join([u\"\\ufeff    {}\".format(key) for key\n",
    "                                       in HOOKS]))\n",
    "  flags.DEFINE_list(\n",
    "      name=\"hooks\", short_name=\"hk\", default=\"LoggingTensorHook\",\n",
    "      help=help_wrap(\n",
    "          u\"A list of (case insensitive) strings to specify the names of \"\n",
    "          u\"training hooks.\\n{}\\n\\ufeff  Example: `--hooks ProfilerHook,\"\n",
    "          u\"ExamplesPerSecondHook`\\n See official.utils.logs.hooks_helper \"\n",
    "          u\"for details.\".format(hook_list_str))\n",
    "  )\n",
    "  key_flags.append(\"hooks\")\n",
    "  \n",
    "  flags.DEFINE_string(\n",
    "      name=\"export_dir\", short_name=\"ed\", default=None,\n",
    "      help=help_wrap(\"If set, a SavedModel serialization of the model will \"\n",
    "                     \"be exported to this directory at the end of training. \"\n",
    "                     \"See the README for more details and relevant links.\")\n",
    "  )\n",
    "  key_flags.append(\"export_dir\")\n",
    "  \n",
    "  flags.DEFINE_enum(\n",
    "      name=\"data_format\", short_name=\"df\", default=\"channels_last\",\n",
    "      enum_values=[\"channels_first\", \"channels_last\"],\n",
    "      help=help_wrap(\n",
    "            \"A flag to override the data format used in the model. \"\n",
    "            \"channels_first provides a performance boost on GPU but is not \"\n",
    "            \"always compatible with CPU. If left unspecified, the data format \"\n",
    "            \"will be chosen automatically based on whether TensorFlow was \"\n",
    "            \"built for CPU or GPU.\"))\n",
    "  key_flags.append(\"data_format\")\n",
    "  \n",
    "  flags.DEFINE_bool(\n",
    "      name=\"shuffle\", short_name=\"sf\", default=True,\n",
    "      help=help_wrap(\"A bool that indicates whether the input should be shuffled.\"))\n",
    "  key_flags.append(\"shuffle\")\n",
    "  \n",
    "  flags.DEFINE_integer(\n",
    "      name=\"shuffle_buffer_size\", short_name=\"sbs\", default=10000,\n",
    "      help=help_wrap(\"Buffer size to use for shuffling. \"\n",
    "                     \"A large buffer size ensures better shuffling, but \"\n",
    "                     \"increases memory usage and startup time.\"))\n",
    "  key_flags.append(\"shuffle_buffer_size\")\n",
    "  \n",
    "  flags.DEFINE_integer(\n",
    "      name=\"prefetch_buffer_size\", short_name=\"pbs\", default=1,\n",
    "      help=help_wrap(\"An int specifying the number of feature batches to prefetch \"\n",
    "                     \"for performance improvement. Recommended value is the number \"\n",
    "                     \"of batches consumed per training step.\"))\n",
    "  key_flags.append(\"prefetch_buffer_size\")\n",
    "  \n",
    "  [flags.declare_key_flag(fl) for fl in key_flags]  # pylint: disable=expression-not-assigned\n",
    "  return key_flags\n",
    "\n",
    "def clear_flags():\n",
    "  for name in list(flags.FLAGS):\n",
    "    delattr(flags.FLAGS, name)\n",
    "\n",
    "def set_defaults(**kwargs):\n",
    "  #flags.FLAGS.remove_flag_values(kwargs.keys())\n",
    "  for key, value in kwargs.items():\n",
    "    flags.FLAGS.set_default(name=key, value=value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lol']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_flags()\n",
    "define_mnist_flags()\n",
    "\n",
    "set_defaults(data_dir='./mnist_data',\n",
    "             model_dir='./mnist_model',\n",
    "             batch_size=50,  #32?\n",
    "             train_epochs=1)\n",
    "\n",
    "flags.FLAGS(['lol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 4\n",
      "inter_op_parallelism_threads: 4\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_tf_random_seed': 2023, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f737d261450>, '_model_dir': './mnist_model', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_model/model.ckpt-8400\n",
      "INFO:tensorflow:Saving checkpoints for 8401 into ./mnist_model/model.ckpt.\n",
      "INFO:tensorflow:learning_rate = 1e-04, cross_entropy = 0.9944068, train_accuracy = 0.6\n",
      "INFO:tensorflow:loss = 0.9944068, step = 8401\n",
      "INFO:tensorflow:global_step/sec: 0.388952\n",
      "INFO:tensorflow:learning_rate = 1e-04, cross_entropy = 0.42406404, train_accuracy = 0.74 (257.108 sec)\n",
      "INFO:tensorflow:loss = 0.42406404, step = 8501 (257.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.388441\n",
      "INFO:tensorflow:learning_rate = 1e-04, cross_entropy = 0.58399546, train_accuracy = 0.7733333 (257.435 sec)\n",
      "INFO:tensorflow:loss = 0.58399546, step = 8601 (257.434 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8611 into ./mnist_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.316857\n",
      "INFO:tensorflow:learning_rate = 1e-04, cross_entropy = 0.5531775, train_accuracy = 0.79 (315.600 sec)\n",
      "INFO:tensorflow:loss = 0.5531775, step = 8701 (315.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.395295\n",
      "INFO:tensorflow:learning_rate = 1e-04, cross_entropy = 0.5612449, train_accuracy = 0.788 (252.975 sec)\n",
      "INFO:tensorflow:loss = 0.5612449, step = 8801 (252.975 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8824 into ./mnist_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.318077\n",
      "INFO:tensorflow:learning_rate = 1e-04, cross_entropy = 0.54922944, train_accuracy = 0.78333336 (314.390 sec)\n",
      "INFO:tensorflow:loss = 0.54922944, step = 8901 (314.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.391802\n",
      "INFO:tensorflow:learning_rate = 1e-04, cross_entropy = 0.554722, train_accuracy = 0.7828571 (255.231 sec)\n",
      "INFO:tensorflow:loss = 0.554722, step = 9001 (255.231 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9037 into ./mnist_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.325067\n",
      "INFO:tensorflow:learning_rate = 1e-04, cross_entropy = 0.55578744, train_accuracy = 0.775 (307.629 sec)\n",
      "INFO:tensorflow:loss = 0.55578744, step = 9101 (307.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.389417\n",
      "INFO:tensorflow:learning_rate = 1e-04, cross_entropy = 0.522329, train_accuracy = 0.7777778 (256.795 sec)\n",
      "INFO:tensorflow:loss = 0.522329, step = 9201 (256.796 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9251 into ./mnist_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.32139\n",
      "INFO:tensorflow:learning_rate = 1e-04, cross_entropy = 0.47291702, train_accuracy = 0.778 (311.148 sec)\n",
      "INFO:tensorflow:loss = 0.47291702, step = 9301 (311.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.379225\n",
      "INFO:tensorflow:learning_rate = 1e-04, cross_entropy = 0.41932064, train_accuracy = 0.78909093 (263.697 sec)\n",
      "INFO:tensorflow:loss = 0.41932064, step = 9401 (263.697 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9459 into ./mnist_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.305301\n",
      "INFO:tensorflow:learning_rate = 1e-04, cross_entropy = 0.25953814, train_accuracy = 0.79833335 (327.544 sec)\n",
      "INFO:tensorflow:loss = 0.25953814, step = 9501 (327.543 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9600 into ./mnist_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.7237094.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-24-19:09:24\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_model/model.ckpt-9600\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-24-19:18:03\n",
      "INFO:tensorflow:Saving dict for global step 9600: accuracy = 0.3964, global_step = 9600, loss = 2.1968265\n",
      "Epoch 0 Evaluation results:\n",
      "\t{'loss': 2.1968265, 'global_step': 9600, 'accuracy': 0.3964}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "run_mnist(flags.FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PLEASE IGNORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: \n",
    "  print image_pixels_train.dtype, image_pixels_train.shape\n",
    "  print image_channels_train.dtype, image_channels_train.shape\n",
    "  print labels_train.dtype, labels_train.shape\n",
    "  print parameters_train.dtype, parameters_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "  print image_pixels_test.dtype, image_pixels_test.shape\n",
    "  print image_channels_test.dtype, image_channels_test.shape\n",
    "  print labels_test.dtype, labels_test.shape\n",
    "  print parameters_test.dtype, parameters_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
